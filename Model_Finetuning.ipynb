{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsFoOb7hTsjIkUO9n4tJ/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wasnaqvi/colab_notebooks/blob/main/Model_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import math\n",
        "from typing import Dict, List, Iterable, Optional, Sequence\n",
        "!pip install arviz\n",
        "!pip install numpyro\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def _extract_names(df: pd.DataFrame, name_col: Optional[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Row-aligned extraction of planet names from df.\n",
        "\n",
        "    If name_col is None or missing, falls back to \"row_{i}\".\n",
        "    \"\"\"\n",
        "    if name_col is not None and name_col in df.columns:\n",
        "        # make robust strings; preserve ordering aligned to df rows\n",
        "        s = df[name_col].astype(str).fillna(\"\")\n",
        "        # optional: strip whitespace\n",
        "        names = [x.strip() for x in s.to_list()]\n",
        "        # if any are empty, replace those with row_i identifiers\n",
        "        out: List[str] = []\n",
        "        for i, nm in enumerate(names):\n",
        "            out.append(nm if nm else f\"row_{i}\")\n",
        "        return out\n",
        "\n",
        "    # fallback: stable identifiers even if there is no name column\n",
        "    return [f\"row_{i}\" for i in range(len(df))]\n",
        "\n",
        "\n",
        "\n",
        "class Survey:\n",
        "    \"\"\"\n",
        "    Survey\n",
        "    ------\n",
        "    A `Survey` represents *one sampled subset* of the parent Hermes dataset.\n",
        "\n",
        "    Think of it as the atomic unit you fit models to:\n",
        "      - It contains the DataFrame slice (`df`) that your model will ingest\n",
        "      - It contains metadata about how it was drawn (survey_id, class_label)\n",
        "      - NEW: it also carries planet/target names forward so you can:\n",
        "          * inspect \"what was actually sampled\"\n",
        "          * label/annotate plots per-survey\n",
        "          * later overlay posterior predictive / fitted curves with planet names\n",
        "\n",
        "    What is stored?\n",
        "    ---------------\n",
        "    Nothing permanent is written anywhere — names live only in-memory inside\n",
        "    each Survey instance:\n",
        "\n",
        "      - `planet_names`: list[str] aligned with df rows\n",
        "      - `planet_index`: dict[str, list[int]] mapping name -> row indices\n",
        "        (list because duplicates can happen; e.g., repeated identifiers)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        survey_id: int,\n",
        "        class_label: str,\n",
        "        df: pd.DataFrame,\n",
        "        *,\n",
        "        name_col: Optional[str] = None,\n",
        "    ):\n",
        "        self.survey_id = int(survey_id)\n",
        "        self.class_label = str(class_label)\n",
        "        self.df = df.reset_index(drop=True)\n",
        "\n",
        "        # NEW: carry forward names (row-aligned)\n",
        "        self.name_col = name_col if (name_col in self.df.columns) else None\n",
        "        self.planet_names: List[str] = _extract_names(self.df, self.name_col)\n",
        "\n",
        "        # NEW: quick lookup from name -> rows inside this survey\n",
        "        self.planet_index: Dict[str, List[int]] = {}\n",
        "        for i, nm in enumerate(self.planet_names):\n",
        "            self.planet_index.setdefault(nm, []).append(i)\n",
        "\n",
        "    @property\n",
        "    def n(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    # targets.\n",
        "\n",
        "    def targets(self) -> List[str]:\n",
        "        \"\"\"Return the planet/target names in this survey (row-aligned).\"\"\"\n",
        "        return list(self.planet_names)\n",
        "\n",
        "    def target_table(self, cols: Optional[Sequence[str]] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Return a small inspection table with names + selected columns.\n",
        "\n",
        "        \"\"\"\n",
        "        out = pd.DataFrame({\"planet_name\": self.planet_names})\n",
        "        if cols:\n",
        "            cols = [c for c in cols if c in self.df.columns]\n",
        "            out = pd.concat([out, self.df.loc[:, cols].reset_index(drop=True)], axis=1)\n",
        "        return out\n",
        "\n",
        "    def row_for_target(self, name: str) -> List[int]:\n",
        "        \"\"\"Return row indices in `df` for a given target name (may be multiple).\"\"\"\n",
        "        return self.planet_index.get(str(name), [])\n",
        "\n",
        "    # leverage and metrics testing.\n",
        "    def leverage(self, col: str = \"logM\") -> float:\n",
        "        \"\"\"\n",
        "        Leverage of the specified column.\n",
        "        Default: leverage of logM.\n",
        "        1D leverage proxy:\n",
        "        L = sqrt( sum_i (x_i - mean(x))^2 )\n",
        "        computed on finite values only.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        - This is essentially sqrt(n) * std(x).\n",
        "        Grows with both spread and sample size.\n",
        "        \"\"\"\n",
        "        arr = self.df[col].to_numpy(float)\n",
        "        m = np.isfinite(arr)\n",
        "        arr = arr[m]\n",
        "        if arr.size < 2:\n",
        "            return 0.0\n",
        "        return float(np.sqrt(np.sum((arr - arr.mean()) ** 2)))\n",
        "\n",
        "    def leverage_2D(self, col_x: str = \"logM\", col_y: str = \"Star Metallicity\") -> float:\n",
        "        \"\"\"\n",
        "        2D leverage proxy as quadrature sum of 1D leverages.\n",
        "        \"\"\"\n",
        "        return float(np.sqrt(self.leverage(col_x) ** 2 + self.leverage(col_y) ** 2))\n",
        "\n",
        "    def leverage_3D(\n",
        "        self,\n",
        "        col_x: str = \"logM\",\n",
        "        col_y: str = \"Star Metallicity\",\n",
        "        col_z: str = \"Planet Radius [Re]\",\n",
        "    ) -> float:\n",
        "        return float(math.cbrt(self.leverage(col_x) ** 2 + self.leverage(col_y) ** 2 + self.leverage(col_z) ** 2))\n",
        "\n",
        "    def mahalanobis_3D(\n",
        "        self,\n",
        "        col_x: str = \"logM\",\n",
        "        col_y: str = \"Star Metallicity\",\n",
        "        col_z: str = \"Planet Radius [Re]\",\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Mean 3D Mahalanobis distance of points in the specified columns,\n",
        "        computed within this survey.\n",
        "\n",
        "        Returns 0 if there are <2 finite rows.\n",
        "        \"\"\"\n",
        "        data = self.df[[col_x, col_y, col_z]].to_numpy(float)\n",
        "        data = data[np.all(np.isfinite(data), axis=1)]\n",
        "        if data.shape[0] < 2:\n",
        "            return 0.0\n",
        "        mean = np.mean(data, axis=0)\n",
        "        cov = np.cov(data, rowvar=False)\n",
        "        inv_cov = np.linalg.inv(cov)\n",
        "        diff = data - mean\n",
        "        m_dist = np.sqrt(np.einsum(\"ij,jk,ik->i\", diff, inv_cov, diff))\n",
        "        return float(np.mean(m_dist))\n",
        "\n",
        "\n",
        "class SurveySampler:\n",
        "    \"\"\"\n",
        "    SurveySampler\n",
        "    -------------\n",
        "    Builds nested mass classes (S1..S4) from HermesData and draws many Survey\n",
        "    objects from them over an N-grid.\n",
        "\n",
        "    Core idea:\n",
        "      - HermesData is the \"parent population\" (your ARIEL MCS or synthetic set)\n",
        "      - SurveySampler constructs *class-conditional subsets* (S1..S4)\n",
        "      - sample_grid draws many Survey realizations without replacement\n",
        "        for each (class, N) combination.\n",
        "\n",
        "    NEW:\n",
        "      - You can specify `name_col` (planet-name column) once in the sampler.\n",
        "      - Each Survey produced will carry those names forward in-memory.\n",
        "\n",
        "    Why this matters:\n",
        "      - Compute survey-level metrics (leverage, WAIC diffs, etc.)\n",
        "        and still have full traceability to the *exact targets* that drove\n",
        "        that result.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hermes: HermesData,\n",
        "        rng_seed: Optional[int] = None,\n",
        "        *,\n",
        "        name_col: Optional[str] = None,\n",
        "    ):\n",
        "        self.hermes = hermes\n",
        "        self.rng = np.random.default_rng(rng_seed)\n",
        "\n",
        "        # NEW: choose / infer planet name column once (used for all surveys)\n",
        "        if name_col is None:\n",
        "            name_col ='Planet Name'\n",
        "        self.name_col = name_col\n",
        "\n",
        "        # build nested mass classes based on logM quantiles\n",
        "        self.mass_classes: Dict[str, pd.DataFrame] = self._build_mass_classes()\n",
        "\n",
        "    def _build_mass_classes(self) -> Dict[str, pd.DataFrame]:\n",
        "        df = self.hermes.df\n",
        "        q25, q50, q75 = df[\"logM\"].quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "        classes: Dict[str, pd.DataFrame] = {}\n",
        "        classes[\"S1\"] = df.copy()\n",
        "        classes[\"S2\"] = df[df[\"logM\"] >= q25].copy()\n",
        "        classes[\"S3\"] = df[df[\"logM\"] >= q50].copy()\n",
        "        classes[\"S4\"] = df[df[\"logM\"] >= q75].copy()\n",
        "        return classes\n",
        "\n",
        "    def sample_grid(\n",
        "        self,\n",
        "        N_grid: Iterable[int],\n",
        "        n_reps_per_combo: int = 10,\n",
        "        class_order: Optional[List[str]] = None,\n",
        "    ) -> List[Survey]:\n",
        "        \"\"\"\n",
        "        For each class in class_order and each N in N_grid,\n",
        "        draw n_reps_per_combo surveys without replacement.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        surveys : list[Survey]\n",
        "            Flat list of Survey objects. Each Survey contains:\n",
        "              - df: sampled targets\n",
        "              - planet_names, planet_index: NEW traceability layer\n",
        "        \"\"\"\n",
        "        if class_order is None:\n",
        "            class_order = [\"S1\", \"S2\", \"S3\", \"S4\"]\n",
        "\n",
        "        surveys: List[Survey] = []\n",
        "        survey_id = 1\n",
        "\n",
        "        for label in class_order:\n",
        "            if label not in self.mass_classes:\n",
        "                continue\n",
        "            subset = self.mass_classes[label]\n",
        "            n_available = len(subset)\n",
        "\n",
        "            for N in N_grid:\n",
        "                if N > n_available:\n",
        "                    continue\n",
        "\n",
        "                for _ in range(n_reps_per_combo):\n",
        "                    rs = int(self.rng.integers(0, 2**32 - 1))\n",
        "                    sample_df = subset.sample(n=N, replace=False, random_state=rs)\n",
        "                    surveys.append(\n",
        "                        Survey(\n",
        "                            survey_id,\n",
        "                            label,\n",
        "                            sample_df,\n",
        "                            name_col=self.name_col,\n",
        "                        )\n",
        "                    )\n",
        "                    survey_id += 1\n",
        "\n",
        "        return surveys\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P79mIkj9iGRu",
        "outputId": "7d7a323e-fc47-4af0-8bcf-0e262382a146"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arviz in /usr/local/lib/python3.12/dist-packages (0.22.0)\n",
            "Requirement already satisfied: setuptools>=60.0.0 in /usr/local/lib/python3.12/dist-packages (from arviz) (75.2.0)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from arviz) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from arviz) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from arviz) (1.16.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arviz) (25.0)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from arviz) (2.2.2)\n",
            "Requirement already satisfied: xarray>=2023.7.0 in /usr/local/lib/python3.12/dist-packages (from arviz) (2025.12.0)\n",
            "Requirement already satisfied: h5netcdf>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from arviz) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from arviz) (4.15.0)\n",
            "Requirement already satisfied: xarray-einstats>=0.3 in /usr/local/lib/python3.12/dist-packages (from arviz) (0.9.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from h5netcdf>=1.0.2->arviz) (3.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->arviz) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->arviz) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->arviz) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->arviz) (1.17.0)\n",
            "Collecting numpyro\n",
            "  Downloading numpyro-0.19.0-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: jax>=0.4.25 in /usr/local/lib/python3.12/dist-packages (from numpyro) (0.7.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.25 in /usr/local/lib/python3.12/dist-packages (from numpyro) (0.7.2)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from numpyro) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from numpyro) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from numpyro) (4.67.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.25->numpyro) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.25->numpyro) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.4.25->numpyro) (1.16.3)\n",
            "Downloading numpyro-0.19.0-py3-none-any.whl (370 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpyro\n",
            "Successfully installed numpyro-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZmabkpmuLY0q"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import asdict, dataclass\n",
        "from multiprocessing import get_context\n",
        "from typing import Any, Dict, List, Mapping, Optional, Sequence, Tuple, Union, Literal\n",
        "\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import pandas as pd\n",
        "\n",
        "import arviz as az\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS\n",
        "from numpyro.infer.util import log_likelihood\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Array1D = npt.NDArray[np.floating]\n",
        "ModelKind = Literal[\"lin\", \"met\"]\n",
        "JaxDType = Union[jnp.float32, jnp.float64]\n",
        "\n",
        "\n",
        "def _as_1d_float(x: npt.ArrayLike) -> Array1D:\n",
        "    return np.asarray(x, dtype=float).ravel()\n",
        "\n",
        "\n",
        "def _finite_mask(*arrays: Array1D) -> npt.NDArray[np.bool_]:\n",
        "    m = np.ones(arrays[0].shape, dtype=bool)\n",
        "    for a in arrays:\n",
        "        m &= np.isfinite(a)\n",
        "    return m\n",
        "\n",
        "\n",
        "def _safe_ptp(x: Array1D, fallback: float = 1.0) -> float:\n",
        "    span = float(np.ptp(x))\n",
        "    return span if np.isfinite(span) and span > 0.0 else float(fallback)\n",
        "\n",
        "\n",
        "def _safe_sd(x: Array1D, fallback: float = 1.0) -> float:\n",
        "    if x.size <= 1:\n",
        "        return float(fallback)\n",
        "    sd = float(np.std(x, ddof=1))\n",
        "    return sd if np.isfinite(sd) and sd > 0.0 else float(fallback)\n",
        "\n",
        "\n",
        "def _et68(x: np.ndarray) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Equal-tailed 68% interval (fast). (Not HDI!!)\n",
        "    \"\"\"\n",
        "    lo, hi = np.quantile(x, [0.16, 0.84])\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "\n",
        "def _scalar_stats_from_idata(idata: az.InferenceData, var: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Fast scalar summaries from posterior samples:\n",
        "      mean, sd, and equal-tailed 68% interval.\n",
        "    \"\"\"\n",
        "    s = np.asarray(idata.posterior[var]).reshape(-1)\n",
        "    mean = float(s.mean())\n",
        "    sd = float(s.std(ddof=1)) if s.size > 1 else 0.0\n",
        "    lo, hi = _et68(s)\n",
        "    return {\"mean\": mean, \"sd\": sd, \"hdi16\": lo, \"hdi84\": hi}\n",
        "\n",
        "\n",
        "# NUTS runner (compute log_likelihood only if you want the WAICs for Model comparison.\n",
        "def _run_nuts(\n",
        "    model_fn,\n",
        "    rng_key: jax.Array,\n",
        "    *,\n",
        "    draws: int,\n",
        "    tune: int,\n",
        "    target_accept: float,\n",
        "    num_chains: int,\n",
        "    model_kwargs: Mapping[str, Any],\n",
        "    compute_log_lik: bool,\n",
        "    chain_method: Literal[\"parallel\", \"vectorized\", \"sequential\"] = \"sequential\",\n",
        ") -> Tuple[MCMC, Optional[Dict[str, jax.Array]]]:\n",
        "    kernel = NUTS(model_fn, target_accept_prob=float(target_accept))\n",
        "    mcmc = MCMC(\n",
        "        kernel,\n",
        "        num_warmup=int(tune),\n",
        "        num_samples=int(draws),\n",
        "        num_chains=int(num_chains),\n",
        "        chain_method=chain_method,\n",
        "        progress_bar=False,\n",
        "    )\n",
        "    mcmc.run(rng_key, **model_kwargs)\n",
        "\n",
        "    if not compute_log_lik:\n",
        "        return mcmc, None\n",
        "\n",
        "    posterior = mcmc.get_samples(group_by_chain=True)\n",
        "    ll = log_likelihood(model_fn, posterior, **model_kwargs)\n",
        "    return mcmc, ll\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Linear + intrinsic scatter (1D Model)\n",
        "# ----------------------------\n",
        "def _linear_scatter_model(\n",
        "    *,\n",
        "    x_c: jax.Array,                 # (N,)\n",
        "    meas_sigma: jax.Array,          # (N,)\n",
        "    y_obs: Optional[jax.Array],     # (N,)\n",
        "    alpha_mu: float,\n",
        "    alpha_sigma: float,\n",
        "    beta_sigma: float,\n",
        "    epsilon_sigma: float,\n",
        ") -> None:\n",
        "    alpha = numpyro.sample(\"alpha\", dist.Normal(alpha_mu, alpha_sigma))\n",
        "    beta = numpyro.sample(\"beta\", dist.Normal(0.0, beta_sigma))\n",
        "    epsilon = numpyro.sample(\"epsilon\", dist.HalfNormal(epsilon_sigma))\n",
        "\n",
        "    alpha_b = alpha[..., None]\n",
        "    beta_b = beta[..., None]\n",
        "    eps_b = epsilon[..., None]\n",
        "\n",
        "    mu = alpha_b + beta_b * x_c\n",
        "    obs_sigma = jnp.sqrt(meas_sigma**2 + eps_b**2)\n",
        "\n",
        "    numpyro.sample(\"y\", dist.Normal(mu, obs_sigma), obs=y_obs)\n",
        "\n",
        "\n",
        "def _fit_leverage_survey_numpyro(\n",
        "    x: npt.ArrayLike,\n",
        "    y_obs: npt.ArrayLike,\n",
        "    y_err_low: npt.ArrayLike,\n",
        "    y_err_high: npt.ArrayLike,\n",
        "    *,\n",
        "    cfg: \"ModelConfig\",\n",
        "    random_seed: int,\n",
        ") -> az.InferenceData:\n",
        "    x_np = _as_1d_float(x)\n",
        "    y_np = _as_1d_float(y_obs)\n",
        "    el_np = _as_1d_float(y_err_low)\n",
        "    eh_np = _as_1d_float(y_err_high)\n",
        "\n",
        "    m = _finite_mask(x_np, y_np, el_np, eh_np)\n",
        "    if int(m.sum()) == 0:\n",
        "        raise ValueError(\"No finite rows after filtering.\")\n",
        "\n",
        "    x_np, y_np, el_np, eh_np = x_np[m], y_np[m], el_np[m], eh_np[m]\n",
        "\n",
        "    meas_sigma_np = 0.5 * (np.abs(el_np) + np.abs(eh_np))\n",
        "    meas_sigma_np = np.clip(meas_sigma_np, 1e-6, None)\n",
        "\n",
        "    x_c_np = x_np - float(x_np.mean())\n",
        "\n",
        "    span_x = _safe_ptp(x_c_np, fallback=1.0)\n",
        "    span_y = _safe_ptp(y_np, fallback=1.0)\n",
        "    y_sd = _safe_sd(y_np, fallback=1.0)\n",
        "\n",
        "    alpha_mu = float(y_np.mean())\n",
        "    alpha_sigma = max(float(y_sd / np.sqrt(y_np.size)), 1e-3)\n",
        "    beta_sigma = max(float(span_y / span_x), 1e-3)\n",
        "    epsilon_sigma = max(float(y_sd), 1e-3)\n",
        "\n",
        "    dtype = cfg.jax_dtype\n",
        "\n",
        "    model_kwargs: Dict[str, Any] = dict(\n",
        "        x_c=jnp.asarray(x_c_np, dtype=dtype),\n",
        "        meas_sigma=jnp.asarray(meas_sigma_np, dtype=dtype),\n",
        "        y_obs=jnp.asarray(y_np, dtype=dtype),\n",
        "        alpha_mu=alpha_mu,\n",
        "        alpha_sigma=alpha_sigma,\n",
        "        beta_sigma=beta_sigma,\n",
        "        epsilon_sigma=epsilon_sigma,\n",
        "    )\n",
        "\n",
        "    rng_key = jax.random.PRNGKey(int(random_seed))\n",
        "    mcmc, ll = _run_nuts(\n",
        "        _linear_scatter_model,\n",
        "        rng_key,\n",
        "        draws=cfg.draws,\n",
        "        tune=cfg.tune,\n",
        "        target_accept=cfg.target_accept,\n",
        "        num_chains=cfg.num_chains,\n",
        "        model_kwargs=model_kwargs,\n",
        "        compute_log_lik=cfg.compute_log_lik,\n",
        "        chain_method=cfg.chain_method,\n",
        "    )\n",
        "\n",
        "    return az.from_numpyro(mcmc, log_likelihood=ll) if ll is not None else az.from_numpyro(mcmc)\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 2) Metallicity model: y on logM and [Fe/H] (3D Model)\n",
        "# -----------------------------------------\n",
        "def _met_model(\n",
        "    *,\n",
        "    x_m_c: jax.Array,               # (N,) mass centered: (m - mean_mass)\n",
        "    x_s_obs: jax.Array,             # (N,) observed stellar metallicity\n",
        "    sig_meas_p: jax.Array,          # (N,) planetary metallicity measurement sigma\n",
        "    sig_meas_s: jax.Array,          # (N,) stellar metallicity measurement sigma\n",
        "    y_planet: Optional[jax.Array],  # (N,) planetary metallicity (e.g., log_x_h2o proxy)\n",
        "    alpha_p_mu: float,\n",
        "    alpha_p_sigma: float,\n",
        "    beta_p_sigma: float,\n",
        "    beta_s_sigma: float,\n",
        "    epsilon_p_sigma: float,\n",
        ") -> None:\n",
        "    # latent true stellar metallicity\n",
        "    x_s_true = numpyro.sample(\"x_s_true\", dist.Normal(x_s_obs, sig_meas_s))\n",
        "\n",
        "    # center stellar metallicity (using latent mean; batching-safe)\n",
        "    x_s_true_c = x_s_true - jnp.mean(x_s_true, axis=-1, keepdims=True)\n",
        "\n",
        "    # priors\n",
        "    alpha_p = numpyro.sample(\"alpha_p\", dist.Normal(alpha_p_mu, alpha_p_sigma))\n",
        "    beta_p  = numpyro.sample(\"beta_p\",  dist.Normal(0.0, beta_p_sigma))\n",
        "    beta_s  = numpyro.sample(\"beta_s\",  dist.Normal(0.0, beta_s_sigma))\n",
        "\n",
        "    epsilon_p = numpyro.sample(\"epsilon\", dist.HalfNormal(epsilon_p_sigma))\n",
        "    numpyro.deterministic(\"sigma_p\", epsilon_p)\n",
        "\n",
        "    # broadcast scalars across N\n",
        "    alpha_b = alpha_p[..., None]\n",
        "    beta_p_b = beta_p[..., None]\n",
        "    beta_s_b = beta_s[..., None]\n",
        "    eps_b = epsilon_p[..., None]\n",
        "\n",
        "    # THE science equation: planetary metallicity ~ mass + stellar metallicity\n",
        "    mu_planetary_metallicity = alpha_b + beta_p_b * x_m_c + beta_s_b * x_s_true_c\n",
        "    numpyro.deterministic(\"mu_planetary_metallicity\", mu_planetary_metallicity)\n",
        "\n",
        "    obs_sigma = jnp.sqrt(sig_meas_p**2 + eps_b**2)\n",
        "\n",
        "    numpyro.sample(\"y_planet\", dist.Normal(mu_planetary_metallicity, obs_sigma), obs=y_planet)\n",
        "\n",
        "\n",
        "def _fit_met_survey_numpyro(\n",
        "    x_mass: npt.ArrayLike,\n",
        "    x_star: npt.ArrayLike,\n",
        "    y_planet: npt.ArrayLike,\n",
        "    y_planet_err_low: npt.ArrayLike,\n",
        "    y_planet_err_high: npt.ArrayLike,\n",
        "    x_star_err_low: npt.ArrayLike,\n",
        "    x_star_err_high: npt.ArrayLike,\n",
        "    *,\n",
        "    cfg: \"ModelConfig\",\n",
        "    random_seed: int,\n",
        ") -> az.InferenceData:\n",
        "    x_m = _as_1d_float(x_mass)\n",
        "    x_s_obs = _as_1d_float(x_star)\n",
        "    yp = _as_1d_float(y_planet)\n",
        "\n",
        "    el_p = _as_1d_float(y_planet_err_low)\n",
        "    eh_p = _as_1d_float(y_planet_err_high)\n",
        "    el_s = _as_1d_float(x_star_err_low)\n",
        "    eh_s = _as_1d_float(x_star_err_high)\n",
        "\n",
        "    m = _finite_mask(x_m, x_s_obs, yp, el_p, eh_p, el_s, eh_s)\n",
        "    x_m, x_s_obs, yp, el_p, eh_p, el_s, eh_s = (\n",
        "        x_m[m], x_s_obs[m], yp[m], el_p[m], eh_p[m], el_s[m], eh_s[m]\n",
        "    )\n",
        "\n",
        "    if x_m.size == 0:\n",
        "        raise ValueError(\"No finite rows for metallicity model in this survey.\")\n",
        "\n",
        "    sig_meas_p_np = 0.5 * (np.abs(el_p) + np.abs(eh_p))\n",
        "    sig_meas_s_np = 0.5 * (np.abs(el_s) + np.abs(eh_s))\n",
        "    sig_meas_p_np = np.clip(sig_meas_p_np, 1e-6, None)\n",
        "    sig_meas_s_np = np.clip(sig_meas_s_np, 1e-6, None)\n",
        "\n",
        "    x_m_c_np = x_m - float(x_m.mean())\n",
        "    x_s_c_obs_np = x_s_obs - float(x_s_obs.mean())  # only for prior scaling\n",
        "\n",
        "    span_xm = _safe_ptp(x_m_c_np, fallback=1.0)\n",
        "    span_xs = _safe_ptp(x_s_c_obs_np, fallback=1.0)\n",
        "    span_yp = _safe_ptp(yp, fallback=1.0)\n",
        "    yp_sd = _safe_sd(yp, fallback=1.0)\n",
        "\n",
        "    alpha_mu = float(yp.mean())\n",
        "    alpha_sigma = max(float(yp_sd / np.sqrt(yp.size)), 1e-3)\n",
        "\n",
        "    beta_m_sigma = max(float(span_yp / span_xm), 1e-3)\n",
        "    beta_s_sigma = max(float(span_yp / span_xs), 1e-3)\n",
        "    epsilon_sigma = max(float(yp_sd), 1e-3)\n",
        "\n",
        "    dtype = cfg.jax_dtype\n",
        "\n",
        "    model_kwargs: Dict[str, Any] = dict(\n",
        "        x_m_c=jnp.asarray(x_m_c_np, dtype=dtype),\n",
        "        x_s_obs=jnp.asarray(x_s_obs, dtype=dtype),\n",
        "        sig_meas_p=jnp.asarray(sig_meas_p_np, dtype=dtype),\n",
        "        sig_meas_s=jnp.asarray(sig_meas_s_np, dtype=dtype),\n",
        "        y_planet=jnp.asarray(yp, dtype=dtype),\n",
        "        alpha_p_mu=alpha_mu,\n",
        "        alpha_p_sigma=alpha_sigma,\n",
        "        beta_p_sigma=beta_m_sigma,   # same heuristic scale as before, just renamed\n",
        "        beta_s_sigma=beta_s_sigma,\n",
        "        epsilon_p_sigma=epsilon_sigma,\n",
        "    )\n",
        "\n",
        "    rng_key = jax.random.PRNGKey(int(random_seed))\n",
        "    mcmc, ll = _run_nuts(\n",
        "        _met_model,\n",
        "        rng_key,\n",
        "        draws=cfg.draws,\n",
        "        tune=cfg.tune,\n",
        "        target_accept=cfg.target_accept,\n",
        "        num_chains=cfg.num_chains,\n",
        "        model_kwargs=model_kwargs,\n",
        "        compute_log_lik=cfg.compute_log_lik,\n",
        "        chain_method=cfg.chain_method,\n",
        "    )\n",
        "\n",
        "    return az.from_numpyro(mcmc, log_likelihood=ll) if ll is not None else az.from_numpyro(mcmc)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Config + parallel helper\n",
        "# -------------------------\n",
        "@dataclass(frozen=True, slots=True)\n",
        "class ModelConfig:\n",
        "    draws: int = 1200\n",
        "    tune: int = 400\n",
        "    target_accept: float = 0.85\n",
        "    num_chains: int = 1\n",
        "    compute_log_lik: bool = False\n",
        "    chain_method: Literal[\"parallel\", \"vectorized\", \"sequential\"] = \"sequential\"\n",
        "    jax_dtype: JaxDType = jnp.float32\n",
        "\n",
        "\n",
        "def _fit_one_job(job: Tuple[ModelKind, Dict[str, Any], Survey, int]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Module-level for multiprocessing spawn pickling.\n",
        "    \"\"\"\n",
        "    kind, cfg_dict, survey, seed = job\n",
        "    cfg = ModelConfig(**cfg_dict)\n",
        "\n",
        "    if kind == \"lin\":\n",
        "        idata = _fit_leverage_survey_numpyro(\n",
        "            survey.df[\"logM\"].to_numpy(),\n",
        "            survey.df[\"log(X_H2O)\"].to_numpy(),\n",
        "            survey.df[\"uncertainty_lower\"].to_numpy(),\n",
        "            survey.df[\"uncertainty_upper\"].to_numpy(),\n",
        "            cfg=cfg,\n",
        "            random_seed=int(seed),\n",
        "        )\n",
        "        a = _scalar_stats_from_idata(idata, \"alpha\")\n",
        "        b = _scalar_stats_from_idata(idata, \"beta\")\n",
        "        e = _scalar_stats_from_idata(idata, \"epsilon\")\n",
        "        return {\n",
        "            \"survey_id\": survey.survey_id,\n",
        "            \"class_label\": survey.class_label,\n",
        "            \"N\": survey.n,\n",
        "            \"L_met\": float(survey.leverage(col=\"log(X_H2O)\")),\n",
        "            \"L_logM\": float(survey.leverage(col=\"logM\")),\n",
        "            \"alpha_mean\": a[\"mean\"], \"alpha_sd\": a[\"sd\"], \"alpha_hdi16\": a[\"hdi16\"], \"alpha_hdi84\": a[\"hdi84\"],\n",
        "            \"beta_mean\":  b[\"mean\"], \"beta_sd\":  b[\"sd\"], \"beta_hdi16\":  b[\"hdi16\"], \"beta_hdi84\":  b[\"hdi84\"],\n",
        "            \"sigma_mean\": e[\"mean\"], \"sigma_sd\": e[\"sd\"], \"sigma_hdi16\": e[\"hdi16\"], \"sigma_hdi84\": e[\"hdi84\"],\n",
        "        }\n",
        "\n",
        "    # kind == \"met\"\n",
        "    idata = _fit_met_survey_numpyro(\n",
        "        survey.df[\"logM\"].to_numpy(),\n",
        "        survey.df[\"Star Metallicity\"].to_numpy(),\n",
        "        survey.df[\"log(X_H2O)\"].to_numpy(),\n",
        "        survey.df[\"uncertainty_lower\"].to_numpy(),\n",
        "        survey.df[\"uncertainty_upper\"].to_numpy(),\n",
        "        survey.df[\"Star Metallicity Error Lower\"].to_numpy(),\n",
        "        survey.df[\"Star Metallicity Error Upper\"].to_numpy(),\n",
        "        cfg=cfg,\n",
        "        random_seed=int(seed),\n",
        "    )\n",
        "    # FIXED: Extract the correct parameter names\n",
        "    a = _scalar_stats_from_idata(idata, \"alpha_p\")\n",
        "    bp = _scalar_stats_from_idata(idata, \"beta_p\")\n",
        "    bs = _scalar_stats_from_idata(idata, \"beta_s\")\n",
        "    e = _scalar_stats_from_idata(idata, \"epsilon\")\n",
        "\n",
        "    return {\n",
        "        \"survey_id\": survey.survey_id,\n",
        "        \"class_label\": survey.class_label,\n",
        "        \"N\": survey.n,\n",
        "        \"L_met\": float(survey.leverage(col=\"log(X_H2O)\")),\n",
        "        \"L_logM\": float(survey.leverage(col=\"logM\")),\n",
        "        \"alpha_p_mean\": a[\"mean\"], \"alpha_p_sd\": a[\"sd\"], \"alpha_p_hdi16\": a[\"hdi16\"], \"alpha_p_hdi84\": a[\"hdi84\"],\n",
        "        \"beta_p_mean\": bp[\"mean\"], \"beta_p_sd\": bp[\"sd\"], \"beta_p_hdi16\": bp[\"hdi16\"], \"beta_p_hdi84\": bp[\"hdi84\"],\n",
        "        \"beta_s_mean\": bs[\"mean\"], \"beta_s_sd\": bs[\"sd\"], \"beta_s_hdi16\": bs[\"hdi16\"], \"beta_s_hdi84\": bs[\"hdi84\"],\n",
        "        \"epsilon_mean\": e[\"mean\"], \"epsilon_sd\": e[\"sd\"], \"epsilon_hdi16\": e[\"hdi16\"], \"epsilon_hdi84\": e[\"hdi84\"],\n",
        "    }\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Public API: Model classes\n",
        "# -------------------------\n",
        "class Model:\n",
        "    \"\"\"\n",
        "    1D Model: Planetary Metallicity ~ Mass only\n",
        "\n",
        "    Fast NumPyro/JAX linear + intrinsic scatter model.\n",
        "\n",
        "    Model equation:\n",
        "        y_planet ~ Normal(alpha + beta * (mass - mean_mass), sqrt(sigma_meas^2 + epsilon^2))\n",
        "\n",
        "    Defaults are tuned for speed (CPU-friendly).\n",
        "    Set compute_log_lik=True only when you need WAIC/LOO.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        draws: int = 1200,\n",
        "        tune: int = 400,\n",
        "        target_accept: float = 0.85,\n",
        "        num_chains: int = 1,\n",
        "        compute_log_lik: bool = False,\n",
        "        chain_method: Literal[\"parallel\", \"vectorized\", \"sequential\"] = \"sequential\",\n",
        "        jax_dtype: JaxDType = jnp.float32,\n",
        "    ) -> None:\n",
        "        self.cfg = ModelConfig(\n",
        "            draws=int(draws),\n",
        "            tune=int(tune),\n",
        "            target_accept=float(target_accept),\n",
        "            num_chains=int(num_chains),\n",
        "            compute_log_lik=bool(compute_log_lik),\n",
        "            chain_method=chain_method,\n",
        "            jax_dtype=jax_dtype,\n",
        "        )\n",
        "\n",
        "    def fit_survey(self, survey: Survey, random_seed: int = 14) -> az.InferenceData:\n",
        "        df = survey.df\n",
        "        return _fit_leverage_survey_numpyro(\n",
        "            df[\"logM\"].to_numpy(),\n",
        "            df[\"log(X_H2O)\"].to_numpy(),\n",
        "            df[\"uncertainty_lower\"].to_numpy(),\n",
        "            df[\"uncertainty_upper\"].to_numpy(),\n",
        "            cfg=self.cfg,\n",
        "            random_seed=int(random_seed),\n",
        "        )\n",
        "\n",
        "    def summarize_single(self, survey: Survey, idata: az.InferenceData) -> Dict[str, Any]:\n",
        "        a = _scalar_stats_from_idata(idata, \"alpha\")\n",
        "        b = _scalar_stats_from_idata(idata, \"beta\")\n",
        "        e = _scalar_stats_from_idata(idata, \"epsilon\")\n",
        "\n",
        "        return {\n",
        "            \"survey_id\": survey.survey_id,\n",
        "            \"class_label\": survey.class_label,\n",
        "            \"N\": survey.n,\n",
        "            \"L_met\": float(survey.leverage(col=\"log(X_H2O)\")),\n",
        "            \"L_logM\": float(survey.leverage(col=\"logM\")),\n",
        "            \"alpha_mean\": a[\"mean\"], \"alpha_sd\": a[\"sd\"], \"alpha_hdi16\": a[\"hdi16\"], \"alpha_hdi84\": a[\"hdi84\"],\n",
        "            \"beta_mean\":  b[\"mean\"], \"beta_sd\":  b[\"sd\"], \"beta_hdi16\":  b[\"hdi16\"], \"beta_hdi84\":  b[\"hdi84\"],\n",
        "            \"sigma_mean\": e[\"mean\"], \"sigma_sd\": e[\"sd\"], \"sigma_hdi16\": e[\"hdi16\"], \"sigma_hdi84\": e[\"hdi84\"],\n",
        "        }\n",
        "\n",
        "    def run_on_surveys(\n",
        "        self,\n",
        "        surveys: Sequence[Survey],\n",
        "        seed: int = 123,\n",
        "        *,\n",
        "        parallel: bool = False,\n",
        "        processes: int = 4,\n",
        "    ) -> pd.DataFrame:\n",
        "        rng = np.random.default_rng(int(seed))\n",
        "\n",
        "        if not parallel:\n",
        "            rows: List[Dict[str, Any]] = []\n",
        "            for survey in surveys:\n",
        "                rs = int(rng.integers(0, 2**32 - 1))\n",
        "                idata = self.fit_survey(survey, random_seed=rs)\n",
        "                rows.append(self.summarize_single(survey, idata))\n",
        "            return pd.DataFrame(rows).sort_values(\"survey_id\").reset_index(drop=True)\n",
        "\n",
        "        jobs: List[Tuple[ModelKind, Dict[str, Any], Survey, int]] = [\n",
        "            (\"lin\", asdict(self.cfg), survey, int(rng.integers(0, 2**32 - 1)))\n",
        "            for survey in surveys\n",
        "        ]\n",
        "        ctx = get_context(\"spawn\")  # macOS safe\n",
        "        with ctx.Pool(processes=int(processes)) as pool:\n",
        "            rows = pool.map(_fit_one_job, jobs)\n",
        "\n",
        "        return pd.DataFrame(rows).sort_values(\"survey_id\").reset_index(drop=True)\n",
        "\n",
        "\n",
        "class MetModel:\n",
        "    \"\"\"\n",
        "    3D Model: Planetary Metallicity ~ Mass + Stellar Metallicity\n",
        "\n",
        "    Fast NumPyro/JAX metallicity model with latent true stellar metallicity.\n",
        "\n",
        "    Model equation:\n",
        "        x_s_true ~ Normal(x_s_obs, sigma_s_meas)  # Latent true stellar metallicity\n",
        "        y_planet ~ Normal(alpha_p + beta_p * (mass - mean_mass) + beta_s * (x_s_true - mean_x_s_true),\n",
        "                          sqrt(sigma_meas^2 + epsilon^2))\n",
        "\n",
        "    Defaults are tuned for speed (CPU-friendly).\n",
        "    Set compute_log_lik=True only when you need WAIC/LOO.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        draws: int = 1200,\n",
        "        tune: int = 400,\n",
        "        target_accept: float = 0.85,\n",
        "        num_chains: int = 1,\n",
        "        compute_log_lik: bool = False,\n",
        "        chain_method: Literal[\"parallel\", \"vectorized\", \"sequential\"] = \"sequential\",\n",
        "        jax_dtype: JaxDType = jnp.float32,\n",
        "    ) -> None:\n",
        "        self.cfg = ModelConfig(\n",
        "            draws=int(draws),\n",
        "            tune=int(tune),\n",
        "            target_accept=float(target_accept),\n",
        "            num_chains=int(num_chains),\n",
        "            compute_log_lik=bool(compute_log_lik),\n",
        "            chain_method=chain_method,\n",
        "            jax_dtype=jax_dtype,\n",
        "        )\n",
        "\n",
        "    def fit_survey(self, survey: Survey, random_seed: int = 14) -> az.InferenceData:\n",
        "        df = survey.df\n",
        "        return _fit_met_survey_numpyro(\n",
        "            df[\"logM\"].to_numpy(),\n",
        "            df[\"Star Metallicity\"].to_numpy(),\n",
        "            df[\"log(X_H2O)\"].to_numpy(),\n",
        "            df[\"uncertainty_lower\"].to_numpy(),\n",
        "            df[\"uncertainty_upper\"].to_numpy(),\n",
        "            df[\"Star Metallicity Error Lower\"].to_numpy(),\n",
        "            df[\"Star Metallicity Error Upper\"].to_numpy(),\n",
        "            cfg=self.cfg,\n",
        "            random_seed=int(random_seed),\n",
        "        )\n",
        "\n",
        "    def summarize_single(self, survey: Survey, idata: az.InferenceData) -> Dict[str, Any]:\n",
        "        # FIXED: Extract correct parameter names\n",
        "        a  = _scalar_stats_from_idata(idata, \"alpha_p\")\n",
        "        bp = _scalar_stats_from_idata(idata, \"beta_p\")\n",
        "        bs = _scalar_stats_from_idata(idata, \"beta_s\")\n",
        "        e  = _scalar_stats_from_idata(idata, \"epsilon\")\n",
        "\n",
        "        return {\n",
        "            \"survey_id\": survey.survey_id,\n",
        "            \"class_label\": survey.class_label,\n",
        "            \"N\": survey.n,\n",
        "            \"L_met\": float(survey.leverage(col=\"log(X_H2O)\")),\n",
        "            \"L_logM\": float(survey.leverage(col=\"logM\")),\n",
        "            \"alpha_p_mean\": a[\"mean\"], \"alpha_p_sd\": a[\"sd\"], \"alpha_p_hdi16\": a[\"hdi16\"], \"alpha_p_hdi84\": a[\"hdi84\"],\n",
        "            \"beta_p_mean\": bp[\"mean\"], \"beta_p_sd\": bp[\"sd\"], \"beta_p_hdi16\": bp[\"hdi16\"], \"beta_p_hdi84\": bp[\"hdi84\"],\n",
        "            \"beta_s_mean\": bs[\"mean\"], \"beta_s_sd\": bs[\"sd\"], \"beta_s_hdi16\": bs[\"hdi16\"], \"beta_s_hdi84\": bs[\"hdi84\"],\n",
        "            \"epsilon_mean\": e[\"mean\"], \"epsilon_sd\": e[\"sd\"], \"epsilon_hdi16\": e[\"hdi16\"], \"epsilon_hdi84\": e[\"hdi84\"],\n",
        "        }\n",
        "\n",
        "    def run_on_surveys(\n",
        "        self,\n",
        "        surveys: Sequence[Survey],\n",
        "        seed: int = 321,\n",
        "        *,\n",
        "        parallel: bool = False,\n",
        "        processes: int = 4,\n",
        "    ) -> pd.DataFrame:\n",
        "        rng = np.random.default_rng(int(seed))\n",
        "\n",
        "        if not parallel:\n",
        "            rows: List[Dict[str, Any]] = []\n",
        "            for survey in surveys:\n",
        "                rs = int(rng.integers(0, 2**32 - 1))\n",
        "                idata = self.fit_survey(survey, random_seed=rs)\n",
        "                rows.append(self.summarize_single(survey, idata))\n",
        "            return pd.DataFrame(rows).sort_values(\"survey_id\").reset_index(drop=True)\n",
        "\n",
        "        jobs: List[Tuple[ModelKind, Dict[str, Any], Survey, int]] = [\n",
        "            (\"met\", asdict(self.cfg), survey, int(rng.integers(0, 2**32 - 1)))\n",
        "            for survey in surveys\n",
        "        ]\n",
        "        ctx = get_context(\"spawn\")  # macOS safe\n",
        "        with ctx.Pool(processes=int(processes)) as pool:\n",
        "            rows = pool.map(_fit_one_job, jobs)\n",
        "\n",
        "        return pd.DataFrame(rows).sort_values(\"survey_id\").reset_index(drop=True)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "mpvqY7-SX778"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 0) Setup ======\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import arviz as az\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS, Predictive\n",
        "from numpyro.infer.util import log_likelihood\n",
        "\n",
        "# Nice readable plots\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": (10, 6),\n",
        "    \"axes.grid\": True,\n",
        "    \"grid.alpha\": 0.25,\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False,\n",
        "    \"font.size\": 12\n",
        "})\n",
        "\n",
        "# Global determinism\n",
        "GLOBAL_SEED = 123\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "\n",
        "# ArviZ config\n",
        "az.rcParams[\"stats.hdi_prob\"] = 0.68\n",
        "az.rcParams[\"plot.max_subplots\"] = 50\n",
        "\n",
        "print(\"numpyro:\", numpyro.__version__)\n",
        "print(\"jax:\", jax.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzZiMimmYjdS",
        "outputId": "24f2e5bc-e291-4450-9c26-aa3108b676b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpyro: 0.19.0\n",
            "jax: 0.7.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/arviz/rcparams.py:345: FutureWarning: stats.hdi_prob is deprecated since 0.18.0, use stats.ci_prob instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"hermes_synthetic_data_0.2.0.csv\"\n",
        "df = pd.read_csv(CSV_PATH).replace([np.inf, -np.inf], np.nan).dropna().reset_index(drop=True)\n",
        "\n",
        "class HermesData:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "hermes = HermesData(df)\n",
        "\n",
        "sampler = SurveySampler(hermes, rng_seed=0, name_col=\"Planet Name\")\n",
        "\n",
        "# pick a grid that actually works for your dataset size\n",
        "N_grid = [20, 40, 80, 120]\n",
        "surveys = sampler.sample_grid(N_grid=N_grid, n_reps_per_combo=5)\n",
        "\n",
        "len(surveys), surveys[0].n, surveys[0].class_label, surveys[0].targets()[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqZzlcnhkDk2",
        "outputId": "434634ec-b717-4668-f788-1a6aa80b2f89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,\n",
              " 20,\n",
              " 'S1',\n",
              " ['WASP-130b', 'HAT-P-45b', 'HAT-P-12b', 'HATS-35b', 'WASP-174b'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== ONE CELL: load CSV -> make surveys -> fit 1D + 3D -> WAIC/LOO compare -> simple PPC mean prediction ======\n",
        "import os, numpy as np, pandas as pd, arviz as az\n",
        "import jax, jax.numpy as jnp\n",
        "from numpyro.infer import Predictive\n",
        "\n",
        "# ---- 0) Locate your dataset (Colab usually: /content/..., this environment: /mnt/data/...)\n",
        "CANDIDATES = [\n",
        "    \"/content/hermes_synthetic_data_0.2.0.csv\",\n",
        "    \"/mnt/data/hermes_synthetic_data_0.2.0.csv\",\n",
        "]\n",
        "DATA_PATH = next((p for p in CANDIDATES if os.path.exists(p)), None)\n",
        "if DATA_PATH is None:\n",
        "    raise FileNotFoundError(f\"Could not find dataset. Tried: {CANDIDATES}\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Loaded:\", DATA_PATH, \"| shape:\", df.shape)\n",
        "print(\"Columns present (subset):\", [c for c in [\"Planet Name\",\"logM\",\"Star Metallicity\",\"log(X_H2O)\",\"uncertainty_lower\",\"uncertainty_upper\",\n",
        "                                              \"Star Metallicity Error Lower\",\"Star Metallicity Error Upper\"] if c in df.columns])\n",
        "\n",
        "# ---- 1) Quick sanity checks on required columns\n",
        "req_1d = [\"logM\",\"log(X_H2O)\",\"uncertainty_lower\",\"uncertainty_upper\"]\n",
        "req_3d = req_1d + [\"Star Metallicity\",\"Star Metallicity Error Lower\",\"Star Metallicity Error Upper\"]\n",
        "missing_1d = [c for c in req_1d if c not in df.columns]\n",
        "missing_3d = [c for c in req_3d if c not in df.columns]\n",
        "if missing_1d: raise ValueError(f\"Missing required 1D columns: {missing_1d}\")\n",
        "if missing_3d: raise ValueError(f\"Missing required 3D columns: {missing_3d}\")\n",
        "\n",
        "# ---- 2) Minimal HermesData wrapper (in case you didn't define it elsewhere)\n",
        "class HermesData:\n",
        "    def __init__(self, df): self.df = df\n",
        "\n",
        "# ---- 3) Ensure your classes exist (SurveySampler, Model, MetModel)\n",
        "for cls in [\"SurveySampler\",\"Model\",\"MetModel\"]:\n",
        "    if cls not in globals():\n",
        "        raise NameError(f\"'{cls}' is not defined in your notebook yet. Run the cells that define it first.\")\n",
        "\n",
        "# ---- 4) Build surveys\n",
        "hermes = HermesData(df)\n",
        "sampler = SurveySampler(hermes, rng_seed=0, name_col=(\"Planet Name\" if \"Planet Name\" in df.columns else None))\n",
        "\n",
        "# choose N grid that is safe given dataset size (and mass-class nesting)\n",
        "N_grid = [20, 40, 80, 120]\n",
        "surveys = sampler.sample_grid(N_grid=N_grid, n_reps_per_combo=5)\n",
        "if len(surveys) == 0:\n",
        "    raise RuntimeError(\"No surveys were produced. Reduce N_grid or check your mass-class construction.\")\n",
        "print(f\"Built {len(surveys)} surveys. Example: survey_id={surveys[0].survey_id}, class={surveys[0].class_label}, N={surveys[0].n}\")\n",
        "print(\"Example targets:\", surveys[0].targets()[:5])\n",
        "\n",
        "# ---- 5) Fit BOTH models across surveys (turn on log-likelihood for WAIC/LOO)\n",
        "m1 = Model(draws=800, tune=400, num_chains=2, compute_log_lik=True, chain_method=\"sequential\", target_accept=0.85)\n",
        "m3 = MetModel(draws=800, tune=400, num_chains=2, compute_log_lik=True, chain_method=\"sequential\", target_accept=0.85)\n",
        "\n",
        "df1 = m1.run_on_surveys(surveys, parallel=True, seed=123)\n",
        "df3 = m3.run_on_surveys(surveys, parallel=True, seed=321)\n",
        "\n",
        "print(\"\\n=== 1D summaries (head) ===\")\n",
        "display(df1.head())\n",
        "print(\"\\n=== 3D summaries (head) ===\")\n",
        "display(df3.head())\n",
        "\n",
        "# ---- 6) Model comparison on the SAME survey (WAIC + LOO)\n",
        "s = surveys[0]\n",
        "idata1 = m1.fit_survey(s, random_seed=0)\n",
        "idata3 = m3.fit_survey(s, random_seed=0)\n",
        "\n",
        "waic1 = az.waic(idata1, var_name=\"y\")\n",
        "waic3 = az.waic(idata3, var_name=\"y_planet\")\n",
        "loo1  = az.loo(idata1,  var_name=\"y\")\n",
        "loo3  = az.loo(idata3,  var_name=\"y_planet\")\n",
        "\n",
        "print(\"\\n=== MODEL COMPARISON (survey_id:\", s.survey_id, \") ===\")\n",
        "print(\"WAIC 1D:\", waic1)\n",
        "print(\"WAIC 3D:\", waic3)\n",
        "print(\"LOO  1D:\", loo1)\n",
        "print(\"LOO  3D:\", loo3)\n",
        "\n",
        "# ---- 7) “Predict / model the mean” for the 3D model: posterior predictive mean (mu_planetary_metallicity)\n",
        "# NOTE: This uses the same centering / measurement-sigma construction as your _fit_met_survey_numpyro.\n",
        "# It calls your _met_model directly, so it will only work if _met_model is defined (it is in your snippet).\n",
        "if \"_met_model\" not in globals():\n",
        "    raise NameError(\"'_met_model' is not defined. Run the cell that defines it (your NumPyro model functions).\")\n",
        "\n",
        "# rebuild the model_kwargs for this survey the same way your fitter does\n",
        "x_m = s.df[\"logM\"].to_numpy(float).ravel()\n",
        "x_s = s.df[\"Star Metallicity\"].to_numpy(float).ravel()\n",
        "yp  = s.df[\"log(X_H2O)\"].to_numpy(float).ravel()\n",
        "el_p = s.df[\"uncertainty_lower\"].to_numpy(float).ravel()\n",
        "eh_p = s.df[\"uncertainty_upper\"].to_numpy(float).ravel()\n",
        "el_s = s.df[\"Star Metallicity Error Lower\"].to_numpy(float).ravel()\n",
        "eh_s = s.df[\"Star Metallicity Error Upper\"].to_numpy(float).ravel()\n",
        "\n",
        "mfinite = np.isfinite(x_m)&np.isfinite(x_s)&np.isfinite(yp)&np.isfinite(el_p)&np.isfinite(eh_p)&np.isfinite(el_s)&np.isfinite(eh_s)\n",
        "x_m, x_s, yp, el_p, eh_p, el_s, eh_s = x_m[mfinite], x_s[mfinite], yp[mfinite], el_p[mfinite], eh_p[mfinite], el_s[mfinite], eh_s[mfinite]\n",
        "sig_meas_p = np.clip(0.5*(np.abs(el_p)+np.abs(eh_p)), 1e-6, None)\n",
        "sig_meas_s = np.clip(0.5*(np.abs(el_s)+np.abs(eh_s)), 1e-6, None)\n",
        "\n",
        "x_m_c = x_m - float(x_m.mean())\n",
        "\n",
        "# heuristic prior scales (match your fitter)\n",
        "span = lambda a: (np.ptp(a) if np.isfinite(np.ptp(a)) and np.ptp(a)>0 else 1.0)\n",
        "sd   = lambda a: (np.std(a, ddof=1) if a.size>1 and np.isfinite(np.std(a, ddof=1)) and np.std(a, ddof=1)>0 else 1.0)\n",
        "\n",
        "span_xm = span(x_m_c)\n",
        "span_xs = span(x_s - float(x_s.mean()))\n",
        "span_yp = span(yp)\n",
        "yp_sd   = sd(yp)\n",
        "\n",
        "alpha_mu = float(yp.mean())\n",
        "alpha_sigma = max(float(yp_sd / np.sqrt(max(yp.size,1))), 1e-3)\n",
        "beta_m_sigma = max(float(span_yp / span_xm), 1e-3)\n",
        "beta_s_sigma = max(float(span_yp / span_xs), 1e-3)\n",
        "epsilon_sigma = max(float(yp_sd), 1e-3)\n",
        "\n",
        "dtype = getattr(m3.cfg, \"jax_dtype\", jnp.float32)\n",
        "model_kwargs = dict(\n",
        "    x_m_c=jnp.asarray(x_m_c, dtype=dtype),\n",
        "    x_s_obs=jnp.asarray(x_s, dtype=dtype),\n",
        "    sig_meas_p=jnp.asarray(sig_meas_p, dtype=dtype),\n",
        "    sig_meas_s=jnp.asarray(sig_meas_s, dtype=dtype),\n",
        "    y_planet=jnp.asarray(yp, dtype=dtype),\n",
        "    alpha_p_mu=alpha_mu,\n",
        "    alpha_p_sigma=alpha_sigma,\n",
        "    beta_p_sigma=beta_m_sigma,\n",
        "    beta_s_sigma=beta_s_sigma,\n",
        "    epsilon_p_sigma=epsilon_sigma,\n",
        ")\n",
        "\n",
        "# pull posterior samples from the numpyro mcmc inside idata3 (via arviz)\n",
        "# easiest: flatten chains into dict-of-arrays\n",
        "posterior = idata3.posterior\n",
        "samples = {\n",
        "    \"alpha_p\": np.asarray(posterior[\"alpha_p\"]).reshape(-1),\n",
        "    \"beta_p\":  np.asarray(posterior[\"beta_p\"]).reshape(-1),\n",
        "    \"beta_s\":  np.asarray(posterior[\"beta_s\"]).reshape(-1),\n",
        "    \"epsilon\": np.asarray(posterior[\"epsilon\"]).reshape(-1),\n",
        "    \"x_s_true\": np.asarray(posterior[\"x_s_true\"]).reshape(-1, x_s.size),  # latent per-object\n",
        "}\n",
        "# convert to jax arrays\n",
        "samples = {k: jnp.asarray(v, dtype=dtype) for k,v in samples.items()}\n",
        "\n",
        "pred = Predictive(_met_model, posterior_samples=samples, return_sites=[\"mu_planetary_metallicity\"])\n",
        "pp = pred(jax.random.PRNGKey(1), **model_kwargs)\n",
        "\n",
        "mu = np.asarray(pp[\"mu_planetary_metallicity\"])  # shape: (S, N)\n",
        "mu_mean = mu.mean(axis=0)\n",
        "mu_lo, mu_hi = np.quantile(mu, [0.16, 0.84], axis=0)\n",
        "\n",
        "pp_table = s.target_table(cols=[\"logM\",\"Star Metallicity\",\"log(X_H2O)\"]).copy()\n",
        "pp_table[\"mu_pred_mean\"] = mu_mean\n",
        "pp_table[\"mu_pred_16\"] = mu_lo\n",
        "pp_table[\"mu_pred_84\"] = mu_hi\n",
        "\n",
        "print(\"\\n=== 3D MEAN PREDICTION TABLE (first 10 rows) ===\")\n",
        "display(pp_table.head(10))\n",
        "\n",
        "# ---- 8) Targeted improvement suggestions (printed so it's all in one cell)\n",
        "print(\"\\n=== SUGGESTIONS TO IMPROVE / FIX ===\")\n",
        "print(\"- 3D leverage: use sqrt(Lx^2+Ly^2+Lz^2) if you want Euclidean; your cbrt is unusual.\")\n",
        "print(\"- Standardize predictors (z-score) in both models; then use tight slope priors like Normal(0,1-2).\")\n",
        "print(\"- Consider StudentT likelihood for y to reduce outlier sensitivity; keeps epsilon from inflating.\")\n",
        "print(\"- If you want prediction as a primary output: add y_rep ~ Normal(mu, obs_sigma) for PPC checks.\")\n",
        "print(\"- If science-motivated: add interaction beta_ms*(mass_centered * stellar_centered), but regularize strongly.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nKbTbGoBmkdm",
        "outputId": "ad20feac-338d-4f1a-99d1-428690cfffe7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: /content/hermes_synthetic_data_0.2.0.csv | shape: (618, 8)\n",
            "Columns present (subset): ['Planet Name', 'logM', 'Star Metallicity', 'log(X_H2O)', 'uncertainty_lower', 'uncertainty_upper', 'Star Metallicity Error Lower', 'Star Metallicity Error Upper']\n",
            "Built 80 surveys. Example: survey_id=1, class=S1, N=20\n",
            "Example targets: ['WASP-130b', 'HAT-P-45b', 'HAT-P-12b', 'HATS-35b', 'WASP-174b']\n",
            "\n",
            "=== 1D summaries (head) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   survey_id class_label   N     L_met    L_logM  alpha_mean  alpha_sd  \\\n",
              "0          1          S1  20  4.194866  2.819956   -0.388206  0.100541   \n",
              "1          2          S1  20  6.248549  5.176308   -0.174265  0.108039   \n",
              "2          3          S1  20  4.248156  3.167812   -0.231403  0.102960   \n",
              "3          4          S1  20  5.425339  3.455950   -0.356343  0.124859   \n",
              "4          5          S1  20  4.183941  3.371722   -0.166096  0.100269   \n",
              "\n",
              "   alpha_hdi16  alpha_hdi84  beta_mean   beta_sd  beta_hdi16  beta_hdi84  \\\n",
              "0    -0.485106    -0.289049  -1.307950  0.160514   -1.464230   -1.159351   \n",
              "1    -0.275104    -0.072130  -1.133526  0.098762   -1.229020   -1.036705   \n",
              "2    -0.331335    -0.129233  -1.157085  0.157111   -1.310681   -1.001448   \n",
              "3    -0.481959    -0.235207  -1.367805  0.180101   -1.550851   -1.180112   \n",
              "4    -0.263216    -0.070132  -1.075944  0.151145   -1.224609   -0.929639   \n",
              "\n",
              "   sigma_mean  sigma_sd  sigma_hdi16  sigma_hdi84  \n",
              "0    0.428851  0.090197     0.342699     0.511407  \n",
              "1    0.466123  0.094702     0.375771     0.557014  \n",
              "2    0.469580  0.093371     0.381959     0.556381  \n",
              "3    0.602425  0.119755     0.488742     0.714870  \n",
              "4    0.445121  0.094785     0.355406     0.536184  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c842f29-dfcc-4046-ba0b-c7606d8629e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_id</th>\n",
              "      <th>class_label</th>\n",
              "      <th>N</th>\n",
              "      <th>L_met</th>\n",
              "      <th>L_logM</th>\n",
              "      <th>alpha_mean</th>\n",
              "      <th>alpha_sd</th>\n",
              "      <th>alpha_hdi16</th>\n",
              "      <th>alpha_hdi84</th>\n",
              "      <th>beta_mean</th>\n",
              "      <th>beta_sd</th>\n",
              "      <th>beta_hdi16</th>\n",
              "      <th>beta_hdi84</th>\n",
              "      <th>sigma_mean</th>\n",
              "      <th>sigma_sd</th>\n",
              "      <th>sigma_hdi16</th>\n",
              "      <th>sigma_hdi84</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>4.194866</td>\n",
              "      <td>2.819956</td>\n",
              "      <td>-0.388206</td>\n",
              "      <td>0.100541</td>\n",
              "      <td>-0.485106</td>\n",
              "      <td>-0.289049</td>\n",
              "      <td>-1.307950</td>\n",
              "      <td>0.160514</td>\n",
              "      <td>-1.464230</td>\n",
              "      <td>-1.159351</td>\n",
              "      <td>0.428851</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>0.342699</td>\n",
              "      <td>0.511407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>6.248549</td>\n",
              "      <td>5.176308</td>\n",
              "      <td>-0.174265</td>\n",
              "      <td>0.108039</td>\n",
              "      <td>-0.275104</td>\n",
              "      <td>-0.072130</td>\n",
              "      <td>-1.133526</td>\n",
              "      <td>0.098762</td>\n",
              "      <td>-1.229020</td>\n",
              "      <td>-1.036705</td>\n",
              "      <td>0.466123</td>\n",
              "      <td>0.094702</td>\n",
              "      <td>0.375771</td>\n",
              "      <td>0.557014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>4.248156</td>\n",
              "      <td>3.167812</td>\n",
              "      <td>-0.231403</td>\n",
              "      <td>0.102960</td>\n",
              "      <td>-0.331335</td>\n",
              "      <td>-0.129233</td>\n",
              "      <td>-1.157085</td>\n",
              "      <td>0.157111</td>\n",
              "      <td>-1.310681</td>\n",
              "      <td>-1.001448</td>\n",
              "      <td>0.469580</td>\n",
              "      <td>0.093371</td>\n",
              "      <td>0.381959</td>\n",
              "      <td>0.556381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>5.425339</td>\n",
              "      <td>3.455950</td>\n",
              "      <td>-0.356343</td>\n",
              "      <td>0.124859</td>\n",
              "      <td>-0.481959</td>\n",
              "      <td>-0.235207</td>\n",
              "      <td>-1.367805</td>\n",
              "      <td>0.180101</td>\n",
              "      <td>-1.550851</td>\n",
              "      <td>-1.180112</td>\n",
              "      <td>0.602425</td>\n",
              "      <td>0.119755</td>\n",
              "      <td>0.488742</td>\n",
              "      <td>0.714870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>4.183941</td>\n",
              "      <td>3.371722</td>\n",
              "      <td>-0.166096</td>\n",
              "      <td>0.100269</td>\n",
              "      <td>-0.263216</td>\n",
              "      <td>-0.070132</td>\n",
              "      <td>-1.075944</td>\n",
              "      <td>0.151145</td>\n",
              "      <td>-1.224609</td>\n",
              "      <td>-0.929639</td>\n",
              "      <td>0.445121</td>\n",
              "      <td>0.094785</td>\n",
              "      <td>0.355406</td>\n",
              "      <td>0.536184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c842f29-dfcc-4046-ba0b-c7606d8629e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c842f29-dfcc-4046-ba0b-c7606d8629e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c842f29-dfcc-4046-ba0b-c7606d8629e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"- If science-motivated: add interaction beta_ms*(mass_centered * stellar_centered), but regularize strongly\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"survey_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"S1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L_met\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9382816658329386,\n        \"min\": 4.183940631594737,\n        \"max\": 6.248549435325063,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.248549435325063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L_logM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9155391947393168,\n        \"min\": 2.8199564838910858,\n        \"max\": 5.176307813045269,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.176307813045269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10326158331086194,\n        \"min\": -0.38820570707321167,\n        \"max\": -0.16609561443328857,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.17426495254039764\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha_sd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010281150525611968,\n        \"min\": 0.10026883333921432,\n        \"max\": 0.12485890090465546,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.10803897678852081\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha_hdi16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10914665690400338,\n        \"min\": -0.48510557413101196,\n        \"max\": -0.26321553468704223,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.27510377049446105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha_hdi84\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09880568540085276,\n        \"min\": -0.28904910326004035,\n        \"max\": -0.07013175755739219,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.07212991237640383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beta_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12359633140236742,\n        \"min\": -1.3678054809570312,\n        \"max\": -1.0759437084197998,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.1335259675979614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beta_sd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03038394628669824,\n        \"min\": 0.09876152873039246,\n        \"max\": 0.18010060489177704,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.09876152873039246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beta_hdi16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1458783032447637,\n        \"min\": -1.5508510398864745,\n        \"max\": -1.2246089315414428,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.2290197896957398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"beta_hdi84\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10636267209618247,\n        \"min\": -1.1801122999191285,\n        \"max\": -0.9296390342712404,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.036704831123352\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sigma_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0690876215726976,\n        \"min\": 0.42885130643844604,\n        \"max\": 0.6024245619773865,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4661233127117157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sigma_sd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011992071651412209,\n        \"min\": 0.09019702672958374,\n        \"max\": 0.11975526809692383,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.09470205754041672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sigma_hdi16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05797696045828214,\n        \"min\": 0.34269864559173585,\n        \"max\": 0.4887415111064911,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3757707059383392\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sigma_hdi84\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08028775860191448,\n        \"min\": 0.5114072632789611,\n        \"max\": 0.7148704099655151,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5570143842697143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 3D summaries (head) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   survey_id class_label   N     L_met    L_logM  alpha_p_mean  alpha_p_sd  \\\n",
              "0          1          S1  20  4.194866  2.819956     -0.386935    0.094408   \n",
              "1          2          S1  20  6.248549  5.176308     -0.168893    0.111721   \n",
              "2          3          S1  20  4.248156  3.167812     -0.239239    0.100166   \n",
              "3          4          S1  20  5.425339  3.455950     -0.361899    0.126475   \n",
              "4          5          S1  20  4.183941  3.371722     -0.167021    0.099485   \n",
              "\n",
              "   alpha_p_hdi16  alpha_p_hdi84  beta_p_mean  ...  beta_p_hdi16  beta_p_hdi84  \\\n",
              "0      -0.480390      -0.292043    -1.305025  ...     -1.468696     -1.139924   \n",
              "1      -0.276965      -0.062561    -1.159143  ...     -1.260370     -1.056963   \n",
              "2      -0.339572      -0.145465    -1.253037  ...     -1.452899     -1.053057   \n",
              "3      -0.489961      -0.236170    -1.283648  ...     -1.496168     -1.072568   \n",
              "4      -0.265871      -0.071332    -1.064862  ...     -1.209729     -0.922037   \n",
              "\n",
              "   beta_s_mean  beta_s_sd  beta_s_hdi16  beta_s_hdi84  epsilon_mean  \\\n",
              "0    -0.118424   0.570072     -0.647559      0.415243      0.442657   \n",
              "1     0.307880   0.517252     -0.189535      0.814093      0.476408   \n",
              "2     0.448713   0.659336     -0.161124      1.074859      0.467214   \n",
              "3    -0.948093   1.117310     -2.005878      0.078908      0.605964   \n",
              "4    -0.257128   0.717822     -0.974457      0.429314      0.457775   \n",
              "\n",
              "   epsilon_sd  epsilon_hdi16  epsilon_hdi84  \n",
              "0    0.100848       0.349033       0.528519  \n",
              "1    0.102245       0.380822       0.569416  \n",
              "2    0.103220       0.369828       0.564617  \n",
              "3    0.128521       0.487944       0.720337  \n",
              "4    0.096823       0.368831       0.550249  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c193cf87-8ba1-4dca-a195-176b3047b3e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_id</th>\n",
              "      <th>class_label</th>\n",
              "      <th>N</th>\n",
              "      <th>L_met</th>\n",
              "      <th>L_logM</th>\n",
              "      <th>alpha_p_mean</th>\n",
              "      <th>alpha_p_sd</th>\n",
              "      <th>alpha_p_hdi16</th>\n",
              "      <th>alpha_p_hdi84</th>\n",
              "      <th>beta_p_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>beta_p_hdi16</th>\n",
              "      <th>beta_p_hdi84</th>\n",
              "      <th>beta_s_mean</th>\n",
              "      <th>beta_s_sd</th>\n",
              "      <th>beta_s_hdi16</th>\n",
              "      <th>beta_s_hdi84</th>\n",
              "      <th>epsilon_mean</th>\n",
              "      <th>epsilon_sd</th>\n",
              "      <th>epsilon_hdi16</th>\n",
              "      <th>epsilon_hdi84</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>4.194866</td>\n",
              "      <td>2.819956</td>\n",
              "      <td>-0.386935</td>\n",
              "      <td>0.094408</td>\n",
              "      <td>-0.480390</td>\n",
              "      <td>-0.292043</td>\n",
              "      <td>-1.305025</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.468696</td>\n",
              "      <td>-1.139924</td>\n",
              "      <td>-0.118424</td>\n",
              "      <td>0.570072</td>\n",
              "      <td>-0.647559</td>\n",
              "      <td>0.415243</td>\n",
              "      <td>0.442657</td>\n",
              "      <td>0.100848</td>\n",
              "      <td>0.349033</td>\n",
              "      <td>0.528519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>6.248549</td>\n",
              "      <td>5.176308</td>\n",
              "      <td>-0.168893</td>\n",
              "      <td>0.111721</td>\n",
              "      <td>-0.276965</td>\n",
              "      <td>-0.062561</td>\n",
              "      <td>-1.159143</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.260370</td>\n",
              "      <td>-1.056963</td>\n",
              "      <td>0.307880</td>\n",
              "      <td>0.517252</td>\n",
              "      <td>-0.189535</td>\n",
              "      <td>0.814093</td>\n",
              "      <td>0.476408</td>\n",
              "      <td>0.102245</td>\n",
              "      <td>0.380822</td>\n",
              "      <td>0.569416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>4.248156</td>\n",
              "      <td>3.167812</td>\n",
              "      <td>-0.239239</td>\n",
              "      <td>0.100166</td>\n",
              "      <td>-0.339572</td>\n",
              "      <td>-0.145465</td>\n",
              "      <td>-1.253037</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.452899</td>\n",
              "      <td>-1.053057</td>\n",
              "      <td>0.448713</td>\n",
              "      <td>0.659336</td>\n",
              "      <td>-0.161124</td>\n",
              "      <td>1.074859</td>\n",
              "      <td>0.467214</td>\n",
              "      <td>0.103220</td>\n",
              "      <td>0.369828</td>\n",
              "      <td>0.564617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>5.425339</td>\n",
              "      <td>3.455950</td>\n",
              "      <td>-0.361899</td>\n",
              "      <td>0.126475</td>\n",
              "      <td>-0.489961</td>\n",
              "      <td>-0.236170</td>\n",
              "      <td>-1.283648</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.496168</td>\n",
              "      <td>-1.072568</td>\n",
              "      <td>-0.948093</td>\n",
              "      <td>1.117310</td>\n",
              "      <td>-2.005878</td>\n",
              "      <td>0.078908</td>\n",
              "      <td>0.605964</td>\n",
              "      <td>0.128521</td>\n",
              "      <td>0.487944</td>\n",
              "      <td>0.720337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>4.183941</td>\n",
              "      <td>3.371722</td>\n",
              "      <td>-0.167021</td>\n",
              "      <td>0.099485</td>\n",
              "      <td>-0.265871</td>\n",
              "      <td>-0.071332</td>\n",
              "      <td>-1.064862</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.209729</td>\n",
              "      <td>-0.922037</td>\n",
              "      <td>-0.257128</td>\n",
              "      <td>0.717822</td>\n",
              "      <td>-0.974457</td>\n",
              "      <td>0.429314</td>\n",
              "      <td>0.457775</td>\n",
              "      <td>0.096823</td>\n",
              "      <td>0.368831</td>\n",
              "      <td>0.550249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c193cf87-8ba1-4dca-a195-176b3047b3e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c193cf87-8ba1-4dca-a195-176b3047b3e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c193cf87-8ba1-4dca-a195-176b3047b3e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:797: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.69 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MODEL COMPARISON (survey_id: 1 ) ===\n",
            "WAIC 1D: Computed from 1600 posterior samples and 20 observations log-likelihood matrix.\n",
            "\n",
            "          Estimate       SE\n",
            "elpd_waic   -14.22     2.27\n",
            "p_waic        1.97        -\n",
            "WAIC 3D: Computed from 1600 posterior samples and 20 observations log-likelihood matrix.\n",
            "\n",
            "          Estimate       SE\n",
            "elpd_waic   -15.46     2.32\n",
            "p_waic        3.19        -\n",
            "\n",
            "There has been a warning during the calculation. Please check the results.\n",
            "LOO  1D: Computed from 1600 posterior samples and 20 observations log-likelihood matrix.\n",
            "\n",
            "         Estimate       SE\n",
            "elpd_loo   -14.30     2.29\n",
            "p_loo        2.05        -\n",
            "------\n",
            "\n",
            "Pareto k diagnostic values:\n",
            "                         Count   Pct.\n",
            "(-Inf, 0.69]   (good)       20  100.0%\n",
            "   (0.69, 1]   (bad)         0    0.0%\n",
            "   (1, Inf)   (very bad)    0    0.0%\n",
            "\n",
            "LOO  3D: Computed from 1600 posterior samples and 20 observations log-likelihood matrix.\n",
            "\n",
            "         Estimate       SE\n",
            "elpd_loo   -15.73     2.40\n",
            "p_loo        3.46        -\n",
            "\n",
            "There has been a warning during the calculation. Please check the results.\n",
            "------\n",
            "\n",
            "Pareto k diagnostic values:\n",
            "                         Count   Pct.\n",
            "(-Inf, 0.69]   (good)       19   95.0%\n",
            "   (0.69, 1]   (bad)         1    5.0%\n",
            "   (1, Inf)   (very bad)    0    0.0%\n",
            "\n",
            "\n",
            "=== 3D MEAN PREDICTION TABLE (first 10 rows) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  planet_name      logM  Star Metallicity  log(X_H2O)  mu_pred_mean  \\\n",
              "0   WASP-130b  0.089905              0.26   -0.977018     -1.048574   \n",
              "1   HAT-P-45b -0.049635              0.07   -1.238024     -0.845491   \n",
              "2   HAT-P-12b -0.675718             -0.29   -0.286658      0.002702   \n",
              "3    HATS-35b  0.087071              0.21   -0.889350     -1.039577   \n",
              "4   WASP-174b -0.481486              0.06    0.105708     -0.284773   \n",
              "5   TOI-1728b -1.074379              0.25   -0.034785      0.456296   \n",
              "6     GJ3929b -2.258848             -0.02    2.363895      2.024007   \n",
              "7    TOI-169b -0.101824              0.24   -0.732672     -0.800578   \n",
              "8      K2-24b -1.179996              0.42    0.448608      0.573105   \n",
              "9      55Cnce -1.609595              0.31    0.948245      1.141733   \n",
              "\n",
              "   mu_pred_16  mu_pred_84  \n",
              "0   -1.195714   -0.906481  \n",
              "1   -0.985207   -0.711530  \n",
              "2   -0.265305    0.267054  \n",
              "3   -1.179217   -0.910943  \n",
              "4   -0.399305   -0.171418  \n",
              "5    0.292571    0.616202  \n",
              "6    1.685980    2.372639  \n",
              "7   -0.923477   -0.677648  \n",
              "8    0.348484    0.790139  \n",
              "9    0.892005    1.384644  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93f9c2e6-689b-446c-a196-26861b9859e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>planet_name</th>\n",
              "      <th>logM</th>\n",
              "      <th>Star Metallicity</th>\n",
              "      <th>log(X_H2O)</th>\n",
              "      <th>mu_pred_mean</th>\n",
              "      <th>mu_pred_16</th>\n",
              "      <th>mu_pred_84</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WASP-130b</td>\n",
              "      <td>0.089905</td>\n",
              "      <td>0.26</td>\n",
              "      <td>-0.977018</td>\n",
              "      <td>-1.048574</td>\n",
              "      <td>-1.195714</td>\n",
              "      <td>-0.906481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAT-P-45b</td>\n",
              "      <td>-0.049635</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-1.238024</td>\n",
              "      <td>-0.845491</td>\n",
              "      <td>-0.985207</td>\n",
              "      <td>-0.711530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAT-P-12b</td>\n",
              "      <td>-0.675718</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.286658</td>\n",
              "      <td>0.002702</td>\n",
              "      <td>-0.265305</td>\n",
              "      <td>0.267054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HATS-35b</td>\n",
              "      <td>0.087071</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.889350</td>\n",
              "      <td>-1.039577</td>\n",
              "      <td>-1.179217</td>\n",
              "      <td>-0.910943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WASP-174b</td>\n",
              "      <td>-0.481486</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.105708</td>\n",
              "      <td>-0.284773</td>\n",
              "      <td>-0.399305</td>\n",
              "      <td>-0.171418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TOI-1728b</td>\n",
              "      <td>-1.074379</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.034785</td>\n",
              "      <td>0.456296</td>\n",
              "      <td>0.292571</td>\n",
              "      <td>0.616202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GJ3929b</td>\n",
              "      <td>-2.258848</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>2.363895</td>\n",
              "      <td>2.024007</td>\n",
              "      <td>1.685980</td>\n",
              "      <td>2.372639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TOI-169b</td>\n",
              "      <td>-0.101824</td>\n",
              "      <td>0.24</td>\n",
              "      <td>-0.732672</td>\n",
              "      <td>-0.800578</td>\n",
              "      <td>-0.923477</td>\n",
              "      <td>-0.677648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>K2-24b</td>\n",
              "      <td>-1.179996</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.448608</td>\n",
              "      <td>0.573105</td>\n",
              "      <td>0.348484</td>\n",
              "      <td>0.790139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>55Cnce</td>\n",
              "      <td>-1.609595</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.948245</td>\n",
              "      <td>1.141733</td>\n",
              "      <td>0.892005</td>\n",
              "      <td>1.384644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93f9c2e6-689b-446c-a196-26861b9859e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93f9c2e6-689b-446c-a196-26861b9859e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93f9c2e6-689b-446c-a196-26861b9859e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"- If science-motivated: add interaction beta_ms*(mass_centered * stellar_centered), but regularize strongly\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"planet_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"K2-24b\",\n          \"HAT-P-45b\",\n          \"TOI-1728b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7954040046144559,\n        \"min\": -2.258848401148215,\n        \"max\": 0.0899051114393979,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -1.1799956931916822,\n          -0.0496351456238769,\n          -1.074378545209171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Star Metallicity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20256411879259914,\n        \"min\": -0.29,\n        \"max\": 0.42,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.42,\n          0.07,\n          0.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log(X_H2O)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0847153378549212,\n        \"min\": -1.238024138389533,\n        \"max\": 2.363895282398052,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4486084477794756,\n          -1.238024138389533,\n          -0.0347849123353322\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mu_pred_mean\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5731045007705688,\n          -0.8454908728599548,\n          0.4562956690788269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mu_pred_16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9672290703583668,\n        \"min\": -1.195713963508606,\n        \"max\": 1.6859799432754516,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.34848434925079347,\n          -0.9852070879936218,\n          0.29257066011428834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mu_pred_84\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.097828514228236,\n        \"min\": -0.9109427428245547,\n        \"max\": 2.3726393795013427,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7901394057273864,\n          -0.7115296745300294,\n          0.6162022352218627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SUGGESTIONS TO IMPROVE / FIX ===\n",
            "- 3D leverage: use sqrt(Lx^2+Ly^2+Lz^2) if you want Euclidean; your cbrt is unusual.\n",
            "- Standardize predictors (z-score) in both models; then use tight slope priors like Normal(0,1-2).\n",
            "- Consider StudentT likelihood for y to reduce outlier sensitivity; keeps epsilon from inflating.\n",
            "- If you want prediction as a primary output: add y_rep ~ Normal(mu, obs_sigma) for PPC checks.\n",
            "- If science-motivated: add interaction beta_ms*(mass_centered * stellar_centered), but regularize strongly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== PAPER-READY PLOTS (6) + PPC z-score residuals PER SURVEY =====================\n",
        "# Assumes you already ran the big cell and therefore have:\n",
        "#   surveys, m1, m3, df1, df3\n",
        "# and m1/m3 were created with compute_log_lik=True\n",
        "#\n",
        "# What this cell does:\n",
        "#   1) Computes WAIC for 1D and 3D for EVERY survey (same data!)\n",
        "#   2) Computes ΔWAIC = WAIC_3D - WAIC_1D  (negative => 3D better)\n",
        "#   3) Computes per-survey PPC z-scores (standardized residuals) for BOTH models\n",
        "#   4) Produces 6 paper-ready plots + saves per-survey PPC residual plots to PDF\n",
        "\n",
        "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt, arviz as az\n",
        "import jax, jax.numpy as jnp\n",
        "\n",
        "# ------------------------------ style ------------------------------\n",
        "plt.rcParams.update({\n",
        "    \"figure.dpi\": 140,\n",
        "    \"savefig.dpi\": 300,\n",
        "    \"font.size\": 12,\n",
        "    \"axes.labelsize\": 13,\n",
        "    \"axes.titlesize\": 13,\n",
        "    \"legend.fontsize\": 11,\n",
        "    \"xtick.labelsize\": 11,\n",
        "    \"ytick.labelsize\": 11,\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False,\n",
        "})\n",
        "\n",
        "OUTDIR = \"paper_plots\"\n",
        "PPCDIR = os.path.join(OUTDIR, \"ppc_by_survey\")\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "os.makedirs(PPCDIR, exist_ok=True)\n",
        "\n",
        "def _clean_ax(ax):\n",
        "    ax.grid(False)\n",
        "    ax.tick_params(direction=\"out\", length=4, width=1)\n",
        "\n",
        "def _finite(*arrs):\n",
        "    m = np.ones_like(arrs[0], dtype=bool)\n",
        "    for a in arrs:\n",
        "        m &= np.isfinite(a)\n",
        "    return m\n",
        "\n",
        "def _et68(x):\n",
        "    lo, hi = np.quantile(x, [0.16, 0.84])\n",
        "    return lo, hi\n",
        "\n",
        "# ------------------------------ helpers: build model kwargs and compute z-scores ------------------------------\n",
        "def _z_scores_1d(survey, idata):\n",
        "    df = survey.df\n",
        "    x = df[\"logM\"].to_numpy(float)\n",
        "    y = df[\"log(X_H2O)\"].to_numpy(float)\n",
        "    el = df[\"uncertainty_lower\"].to_numpy(float)\n",
        "    eh = df[\"uncertainty_upper\"].to_numpy(float)\n",
        "\n",
        "    m = _finite(x, y, el, eh)\n",
        "    x, y, el, eh = x[m], y[m], el[m], eh[m]\n",
        "\n",
        "    meas_sigma = np.clip(0.5*(np.abs(el)+np.abs(eh)), 1e-6, None)\n",
        "    x_c = x - x.mean()\n",
        "\n",
        "    post = idata.posterior\n",
        "    alpha = np.asarray(post[\"alpha\"]).reshape(-1)\n",
        "    beta  = np.asarray(post[\"beta\"]).reshape(-1)\n",
        "    eps   = np.asarray(post[\"epsilon\"]).reshape(-1)\n",
        "\n",
        "    # posterior mean of mu_i across draws\n",
        "    # mu_draws shape: (S, N)\n",
        "    mu_draws = alpha[:, None] + beta[:, None]*x_c[None, :]\n",
        "    mu_mean  = mu_draws.mean(axis=0)\n",
        "\n",
        "    # use posterior mean epsilon for z-score denominator (stable & interpretable)\n",
        "    eps_mean = float(eps.mean())\n",
        "    sig_tot  = np.sqrt(meas_sigma**2 + eps_mean**2)\n",
        "\n",
        "    z = (y - mu_mean) / sig_tot\n",
        "    return {\n",
        "        \"x\": x, \"x_c\": x_c, \"y\": y, \"meas_sigma\": meas_sigma,\n",
        "        \"mu_mean\": mu_mean, \"eps_mean\": eps_mean, \"z\": z, \"mask_used\": m\n",
        "    }\n",
        "\n",
        "def _z_scores_3d(survey, idata):\n",
        "    df = survey.df\n",
        "    xm = df[\"logM\"].to_numpy(float)\n",
        "    xs = df[\"Star Metallicity\"].to_numpy(float)\n",
        "    y  = df[\"log(X_H2O)\"].to_numpy(float)\n",
        "    elp = df[\"uncertainty_lower\"].to_numpy(float)\n",
        "    ehp = df[\"uncertainty_upper\"].to_numpy(float)\n",
        "    els = df[\"Star Metallicity Error Lower\"].to_numpy(float)\n",
        "    ehs = df[\"Star Metallicity Error Upper\"].to_numpy(float)\n",
        "\n",
        "    m = _finite(xm, xs, y, elp, ehp, els, ehs)\n",
        "    xm, xs, y, elp, ehp, els, ehs = xm[m], xs[m], y[m], elp[m], ehp[m], els[m], ehs[m]\n",
        "\n",
        "    sig_p = np.clip(0.5*(np.abs(elp)+np.abs(ehp)), 1e-6, None)\n",
        "\n",
        "    xm_c = xm - xm.mean()\n",
        "\n",
        "    post = idata.posterior\n",
        "    alpha = np.asarray(post[\"alpha_p\"]).reshape(-1)\n",
        "    bp    = np.asarray(post[\"beta_p\"]).reshape(-1)\n",
        "    bs    = np.asarray(post[\"beta_s\"]).reshape(-1)\n",
        "    eps   = np.asarray(post[\"epsilon\"]).reshape(-1)\n",
        "\n",
        "    # latent x_s_true is in posterior with shape (chain, draw, N) -> flatten to (S, N)\n",
        "    x_s_true = np.asarray(post[\"x_s_true\"]).reshape(-1, xs.size)\n",
        "\n",
        "    # center latent per draw (consistent with your model)\n",
        "    x_s_true_c = x_s_true - x_s_true.mean(axis=1, keepdims=True)\n",
        "\n",
        "    mu_draws = alpha[:, None] + bp[:, None]*xm_c[None, :] + bs[:, None]*x_s_true_c\n",
        "    mu_mean  = mu_draws.mean(axis=0)\n",
        "\n",
        "    eps_mean = float(eps.mean())\n",
        "    sig_tot  = np.sqrt(sig_p**2 + eps_mean**2)\n",
        "    z = (y - mu_mean) / sig_tot\n",
        "\n",
        "    return {\n",
        "        \"xm\": xm, \"xm_c\": xm_c, \"xs\": xs, \"y\": y, \"sig_p\": sig_p,\n",
        "        \"mu_mean\": mu_mean, \"eps_mean\": eps_mean, \"z\": z, \"mask_used\": m,\n",
        "        \"bp_mean\": float(bp.mean()), \"bs_mean\": float(bs.mean())\n",
        "    }\n",
        "\n",
        "def _survey_metrics(survey):\n",
        "    # predictors you asked about\n",
        "    out = {\n",
        "        \"survey_id\": survey.survey_id,\n",
        "        \"class_label\": survey.class_label,\n",
        "        \"N\": survey.n,\n",
        "        \"L_logM\": float(survey.leverage(col=\"logM\")),\n",
        "        \"L_met\": float(survey.leverage(col=\"log(X_H2O)\")),\n",
        "    }\n",
        "    # optional 3D leverage / Mahalanobis if cols exist\n",
        "    if \"Planet Radius [Re]\" in survey.df.columns and \"Star Metallicity\" in survey.df.columns:\n",
        "        out[\"L_3D\"] = float(survey.leverage_3D(col_x=\"logM\", col_y=\"Star Metallicity\", col_z=\"Planet Radius [Re]\"))\n",
        "        out[\"Mahal_3D\"] = float(survey.mahalanobis_3D(col_x=\"logM\", col_y=\"Star Metallicity\", col_z=\"Planet Radius [Re]\"))\n",
        "    else:\n",
        "        out[\"L_3D\"] = np.nan\n",
        "        out[\"Mahal_3D\"] = np.nan\n",
        "    return out\n",
        "\n",
        "# ------------------------------ compute WAIC + z-scores for ALL surveys ------------------------------\n",
        "rows = []\n",
        "ppc_rows = []\n",
        "\n",
        "print(\"Computing per-survey fits (again) for WAIC + PPC z-scores...\")\n",
        "print(\"Note: This can take a while because it runs BOTH models per survey.\")\n",
        "\n",
        "for s in surveys:\n",
        "    # fit both models on the SAME survey (same data)\n",
        "    id1 = m1.fit_survey(s, random_seed=0)\n",
        "    id3 = m3.fit_survey(s, random_seed=0)\n",
        "\n",
        "    # WAIC (lower is better)\n",
        "    w1 = az.waic(id1, var_name=\"y\")\n",
        "    w3 = az.waic(id3, var_name=\"y_planet\")\n",
        "\n",
        "    # store model parameter summaries from existing dfs (optional)\n",
        "    met = _survey_metrics(s)\n",
        "\n",
        "    # 1D z-scores\n",
        "    z1 = _z_scores_1d(s, id1)\n",
        "    # 3D z-scores\n",
        "    z3 = _z_scores_3d(s, id3)\n",
        "\n",
        "    # summary residual diagnostics per survey\n",
        "    def _z_summary(z):\n",
        "        z = np.asarray(z)\n",
        "        return {\n",
        "            \"z_mean\": float(np.mean(z)),\n",
        "            \"z_sd\": float(np.std(z, ddof=1)) if z.size > 1 else np.nan,\n",
        "            \"frac_|z|>2\": float(np.mean(np.abs(z) > 2.0)),\n",
        "            \"frac_|z|>3\": float(np.mean(np.abs(z) > 3.0)),\n",
        "            \"rmse_z\": float(np.sqrt(np.mean(z**2))),\n",
        "        }\n",
        "\n",
        "    # ArviZ: WAIC is not provided directly; compute it from elpd_waic\n",
        "    waic_1d = float(-2.0 * w1.elpd_waic)\n",
        "    waic_3d = float(-2.0 * w3.elpd_waic)\n",
        "\n",
        "    met_row = dict(\n",
        "    **met,\n",
        "\n",
        "    elpd_waic_1d=float(w1.elpd_waic),\n",
        "    elpd_waic_3d=float(w3.elpd_waic),\n",
        "    pwaic_1d=float(w1.p_waic),\n",
        "    pwaic_3d=float(w3.p_waic),\n",
        "\n",
        "    waic_1d=waic_1d,\n",
        "    waic_3d=waic_3d,\n",
        "\n",
        "    d_elpd_waic=float(w3.elpd_waic - w1.elpd_waic),   # positive => 3D better\n",
        "    d_waic=float(waic_3d - waic_1d),                  # negative => 3D better\n",
        ")\n",
        "\n",
        "    rows.append(met_row)\n",
        "\n",
        "    ppc_rows.append({\n",
        "        \"survey_id\": s.survey_id, \"class_label\": s.class_label, \"N\": s.n,\n",
        "        **{f\"1d_{k}\": v for k,v in _z_summary(z1[\"z\"]).items()},\n",
        "        **{f\"3d_{k}\": v for k,v in _z_summary(z3[\"z\"]).items()},\n",
        "    })\n",
        "\n",
        "    # --------- SAVE per-survey PPC residual plots (paper-clean) ----------\n",
        "    # 2-panel: z vs logM for both models, same y-limits\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10.5, 3.6), sharey=True)\n",
        "    for ax in axs: _clean_ax(ax)\n",
        "\n",
        "    # 1D\n",
        "    axs[0].axhline(0, lw=1)\n",
        "    axs[0].axhline( 2, lw=0.8, ls=\"--\")\n",
        "    axs[0].axhline(-2, lw=0.8, ls=\"--\")\n",
        "    axs[0].scatter(z1[\"x\"], z1[\"z\"], s=18, alpha=0.8)\n",
        "    axs[0].set_title(f\"Survey {s.survey_id} • 1D\")\n",
        "    axs[0].set_xlabel(\"logM\")\n",
        "    axs[0].set_ylabel(\"PPC z-score  (y - E[y|x]) / σ_total\")\n",
        "\n",
        "    # 3D\n",
        "    axs[1].axhline(0, lw=1)\n",
        "    axs[1].axhline( 2, lw=0.8, ls=\"--\")\n",
        "    axs[1].axhline(-2, lw=0.8, ls=\"--\")\n",
        "    axs[1].scatter(z3[\"xm\"], z3[\"z\"], s=18, alpha=0.8)\n",
        "    axs[1].set_title(f\"Survey {s.survey_id} • 3D\")\n",
        "    axs[1].set_xlabel(\"logM\")\n",
        "\n",
        "    # consistent y-limits (robust)\n",
        "    z_all = np.concatenate([np.asarray(z1[\"z\"]), np.asarray(z3[\"z\"])])\n",
        "    lim = np.nanquantile(np.abs(z_all), 0.98)\n",
        "    lim = max(2.5, float(lim))\n",
        "    axs[0].set_ylim(-lim, lim)\n",
        "\n",
        "    fig.suptitle(f\"PPC residuals (z-scores): class={s.class_label}, N={s.n}\", y=1.03)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(PPCDIR, f\"ppc_z_survey_{s.survey_id:04d}.pdf\"), bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "metrics_df = pd.DataFrame(rows).sort_values([\"class_label\",\"N\",\"survey_id\"]).reset_index(drop=True)\n",
        "ppc_df = pd.DataFrame(ppc_rows).sort_values([\"class_label\",\"N\",\"survey_id\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Computed metrics_df:\", metrics_df.shape, \" | ppc_df:\", ppc_df.shape)\n",
        "display(metrics_df.head())\n",
        "display(ppc_df.head())\n",
        "\n",
        "# ===================== PLOT 1: ΔWAIC vs N (Does 3D help for SAME data?) =====================\n",
        "fig, ax = plt.subplots(figsize=(7.2, 4.6))\n",
        "_clean_ax(ax)\n",
        "\n",
        "# jitter N slightly for visibility\n",
        "rng = np.random.default_rng(0)\n",
        "xj = metrics_df[\"N\"].to_numpy(float) + rng.normal(0, 0.6, size=len(metrics_df))\n",
        "\n",
        "for lab in sorted(metrics_df[\"class_label\"].unique()):\n",
        "    d = metrics_df[metrics_df[\"class_label\"] == lab]\n",
        "    x = d[\"N\"].to_numpy(float) + rng.normal(0, 0.6, size=len(d))\n",
        "    ax.scatter(x, d[\"d_waic\"], s=22, alpha=0.8, label=lab)\n",
        "\n",
        "ax.axhline(0, lw=1)\n",
        "ax.set_xlabel(\"Survey size N\")\n",
        "ax.set_ylabel(\"ΔWAIC = WAIC(3D) − WAIC(1D)   (negative ⇒ 3D better)\")\n",
        "ax.set_title(\"Key science question: does adding stellar metallicity improve out-of-sample fit?\")\n",
        "ax.legend(frameon=False, ncols=2)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUTDIR, \"plot1_deltaWAIC_vs_N.pdf\"), bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== PLOT 2: Identifiability of beta_s  (|beta_s|/sd) vs N =====================\n",
        "fig, ax = plt.subplots(figsize=(7.2, 4.6))\n",
        "_clean_ax(ax)\n",
        "\n",
        "sig = np.abs(metrics_df[\"beta_s_mean\"]) / np.clip(metrics_df[\"beta_s_sd\"], 1e-12, None)\n",
        "\n",
        "for lab in sorted(metrics_df[\"class_label\"].unique()):\n",
        "    d = metrics_df[metrics_df[\"class_label\"] == lab]\n",
        "    sig_d = np.abs(d[\"beta_s_mean\"]) / np.clip(d[\"beta_s_sd\"], 1e-12, None)\n",
        "    ax.scatter(d[\"N\"], sig_d, s=22, alpha=0.8, label=lab)\n",
        "\n",
        "ax.axhline(1, lw=0.9, ls=\"--\")\n",
        "ax.set_xlabel(\"Survey size N\")\n",
        "ax.set_ylabel(r\"$|\\beta_s|/\\mathrm{sd}(\\beta_s)$  (≈ significance)\")\n",
        "ax.set_title(\"Is the stellar-metallicity slope actually identified?\")\n",
        "ax.legend(frameon=False, ncols=2)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUTDIR, \"plot2_betaS_significance_vs_N.pdf\"), bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== PLOT 3: Posterior mean relation slices (3D model) =====================\n",
        "# We draw three [Fe/H] slices using posterior means and posterior covariance-free bands via posterior draws.\n",
        "# Choose three representative stellar metallicities from GLOBAL data percentiles.\n",
        "xs_all = df[\"Star Metallicity\"].to_numpy(float)\n",
        "xs_vals = np.quantile(xs_all[np.isfinite(xs_all)], [0.2, 0.5, 0.8])\n",
        "xs_vals = [float(v) for v in xs_vals]\n",
        "\n",
        "# Use ONE representative survey (largest N) to show the learned relation cleanly.\n",
        "s_ref = max(surveys, key=lambda s: s.n)\n",
        "id3_ref = m3.fit_survey(s_ref, random_seed=1)\n",
        "\n",
        "post = id3_ref.posterior\n",
        "alpha = np.asarray(post[\"alpha_p\"]).reshape(-1)\n",
        "bp    = np.asarray(post[\"beta_p\"]).reshape(-1)\n",
        "bs    = np.asarray(post[\"beta_s\"]).reshape(-1)\n",
        "eps   = np.asarray(post[\"epsilon\"]).reshape(-1)\n",
        "\n",
        "# grid in mass (centered at the reference survey mean mass)\n",
        "xm_ref = s_ref.df[\"logM\"].to_numpy(float)\n",
        "m0 = float(np.mean(xm_ref[np.isfinite(xm_ref)]))\n",
        "m_grid = np.linspace(np.nanmin(xm_ref), np.nanmax(xm_ref), 120)\n",
        "m_c_grid = m_grid - m0\n",
        "\n",
        "# For slices, we set x_s_true_c to (xs - mean_xs_true). We approximate mean_xs_true by mean observed in survey.\n",
        "xs0 = float(np.mean(s_ref.df[\"Star Metallicity\"].to_numpy(float)))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7.2, 4.8))\n",
        "_clean_ax(ax)\n",
        "\n",
        "for xs_fix in xs_vals:\n",
        "    xs_c = xs_fix - xs0\n",
        "    mu_draws = alpha[:, None] + bp[:, None]*m_c_grid[None, :] + bs[:, None]*xs_c\n",
        "    mu_mean = mu_draws.mean(axis=0)\n",
        "    lo, hi = np.quantile(mu_draws, [0.16, 0.84], axis=0)\n",
        "    ax.plot(m_grid, mu_mean, lw=2, label=f\"[Fe/H] ≈ {xs_fix:+.2f}\")\n",
        "    ax.fill_between(m_grid, lo, hi, alpha=0.20)\n",
        "\n",
        "# overlay the survey points faintly\n",
        "y_ref = s_ref.df[\"log(X_H2O)\"].to_numpy(float)\n",
        "ax.scatter(xm_ref, y_ref, s=18, alpha=0.35)\n",
        "\n",
        "ax.set_xlabel(\"logM\")\n",
        "ax.set_ylabel(r\"Predicted mean log(X_H2O)\")\n",
        "ax.set_title(f\"3D model mean relation: mass trends at fixed stellar metallicity (survey {s_ref.survey_id}, N={s_ref.n})\")\n",
        "ax.legend(frameon=False)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUTDIR, \"plot3_3D_mean_relation_slices.pdf\"), bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== PLOT 4: PPC residuals summary across surveys (1D vs 3D) =====================\n",
        "# Show RMSE(z) vs N for BOTH models. (Lower is better; ~1 is well-calibrated.)\n",
        "fig, ax = plt.subplots(figsize=(7.2, 4.6))\n",
        "_clean_ax(ax)\n",
        "\n",
        "for lab in sorted(ppc_df[\"class_label\"].unique()):\n",
        "    d = ppc_df[ppc_df[\"class_label\"] == lab]\n",
        "    ax.scatter(d[\"N\"], d[\"1d_rmse_z\"], s=22, alpha=0.75, marker=\"o\", label=f\"{lab} 1D\")\n",
        "    ax.scatter(d[\"N\"], d[\"3d_rmse_z\"], s=22, alpha=0.75, marker=\"^\", label=f\"{lab} 3D\")\n",
        "\n",
        "ax.axhline(1.0, lw=0.9, ls=\"--\")\n",
        "ax.set_xlabel(\"Survey size N\")\n",
        "ax.set_ylabel(\"RMSE of PPC z-scores (ideal ≈ 1)\")\n",
        "ax.set_title(\"Predictive calibration: does 3D reduce standardized residuals?\")\n",
        "ax.legend(frameon=False, ncols=2)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUTDIR, \"plot4_ppc_rmseZ_vs_N.pdf\"), bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== PLOT 5: ΔWAIC vs 3D leverage metrics (Is leverage predictive?) =====================\n",
        "# We'll use Mahalanobis_3D if available, else fall back to L_3D (may be NaN if radius not present).\n",
        "fig, ax = plt.subplots(figsize=(7.2, 4.6))\n",
        "_clean_ax(ax)\n",
        "\n",
        "use_x = \"Mahal_3D\" if np.isfinite(metrics_df[\"Mahal_3D\"]).any() else \"L_3D\"\n",
        "d = metrics_df[np.isfinite(metrics_df[use_x])].copy()\n",
        "\n",
        "if d.empty:\n",
        "    print(\"PLOT 5 skipped: No 3D leverage columns available (need Star Metallicity + Planet Radius [Re]).\")\n",
        "else:\n",
        "    for lab in sorted(d[\"class_label\"].unique()):\n",
        "        dd = d[d[\"class_label\"] == lab]\n",
        "        ax.scatter(dd[use_x], dd[\"d_waic\"], s=22, alpha=0.8, label=lab)\n",
        "    ax.axhline(0, lw=1)\n",
        "    ax.set_xlabel(use_x)\n",
        "    ax.set_ylabel(\"ΔWAIC = WAIC(3D) − WAIC(1D)   (negative ⇒ 3D better)\")\n",
        "    ax.set_title(\"Is 3D leverage a predictor of when the 3D model helps?\")\n",
        "    ax.legend(frameon=False, ncols=2)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(OUTDIR, f\"plot5_deltaWAIC_vs_{use_x}.pdf\"), bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "# ===================== PLOT 6: Joint posterior (beta_p vs beta_s) =====================\n",
        "# Use the same reference survey posterior as Plot 3 (cleanest).\n",
        "bp_s = np.asarray(id3_ref.posterior[\"beta_p\"]).reshape(-1)\n",
        "bs_s = np.asarray(id3_ref.posterior[\"beta_s\"]).reshape(-1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5.8, 5.4))\n",
        "_clean_ax(ax)\n",
        "\n",
        "ax.scatter(bp_s[::max(1, bp_s.size//4000)], bs_s[::max(1, bs_s.size//4000)], s=10, alpha=0.25)\n",
        "ax.set_xlabel(r\"$\\beta_p$  (mass slope)\")\n",
        "ax.set_ylabel(r\"$\\beta_s$  (stellar metallicity slope)\")\n",
        "ax.set_title(f\"Joint posterior: β_p vs β_s (survey {s_ref.survey_id}, N={s_ref.n})\")\n",
        "\n",
        "# show 68% intervals as lines\n",
        "bp_lo, bp_hi = _et68(bp_s)\n",
        "bs_lo, bs_hi = _et68(bs_s)\n",
        "ax.axvline(bp_lo, lw=0.9, ls=\"--\"); ax.axvline(bp_hi, lw=0.9, ls=\"--\")\n",
        "ax.axhline(bs_lo, lw=0.9, ls=\"--\"); ax.axhline(bs_hi, lw=0.9, ls=\"--\")\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUTDIR, \"plot6_jointposterior_betaP_betaS.pdf\"), bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# ===================== (Extra) A single “answer plot”: ΔWAIC vs L_logM (Is 1D leverage enough?) =====================\n",
        "# This directly tests: is leverage even a good predictor? (your existing metric)\n",
        "fig, ax = plt.subplots(figsize=(7.2, 4.6))\n",
        "_clean_ax(ax)\n",
        "for lab in sorted(metrics_df[\"class_label\"].unique()):\n",
        "    dd = metrics_df[metrics_df[\"class_label\"] == lab]\n",
        "    ax.scatter(dd[\"L_logM\"], dd[\"d_waic\"], s=22, alpha=0.8, label=lab)\n",
        "ax.axhline(0, lw=1)\n",
        "ax.set_xlabel(\"1D leverage L_logM\")\n",
        "ax.set_ylabel(\"ΔWAIC = WAIC(3D) − WAIC(1D)   (negative ⇒ 3D better)\")\n",
        "ax.set_title(\"Is 1D leverage sufficient to predict when 3D helps?\")\n",
        "ax.legend(frameon=False, ncols=2)\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(OUTDIR, \"extra_deltaWAIC_vs_LlogM.pdf\"), bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSaved:\")\n",
        "print(\" - 6 paper plots to:\", OUTDIR)\n",
        "print(\" - per-survey PPC residual PDFs to:\", PPCDIR)\n",
        "print(\"\\nKey science read-off:\")\n",
        "print(\" - Plot 1 (ΔWAIC vs N): if points are mostly >0 → 3D not justified; mostly <0 → 3D helps.\")\n",
        "print(\" - Plot 5 (ΔWAIC vs 3D leverage): correlation → leverage predicts when 3D helps; no trend → leverage not enough.\")\n",
        "print(\" - PPC per-survey PDFs: look for structure in z vs logM; persistent structure means model misspecification.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X9phXkf75Ape",
        "outputId": "95d9dedf-cd44-4efb-882e-18cbc43ecf9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing per-survey fits (again) for WAIC + PPC z-scores...\n",
            "Note: This can take a while because it runs BOTH models per survey.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/arviz/stats/stats.py:1667: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
            "See http://arxiv.org/abs/1507.04544 for details\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed metrics_df: (80, 15)  | ppc_df: (80, 13)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   survey_id class_label   N    L_logM     L_met  L_3D  Mahal_3D  \\\n",
              "0          1          S1  20  2.819956  4.194866   NaN       NaN   \n",
              "1          2          S1  20  5.176308  6.248549   NaN       NaN   \n",
              "2          3          S1  20  3.167812  4.248156   NaN       NaN   \n",
              "3          4          S1  20  3.455950  5.425339   NaN       NaN   \n",
              "4          5          S1  20  3.371722  4.183941   NaN       NaN   \n",
              "\n",
              "   elpd_waic_1d  elpd_waic_3d  pwaic_1d  pwaic_3d    waic_1d    waic_3d  \\\n",
              "0    -14.223797    -15.461509  1.972777  3.187070  28.447594  30.923018   \n",
              "1    -16.128995    -16.794204  3.074055  3.567468  32.257989  33.588408   \n",
              "2    -15.659566    -16.153688  2.009456  3.010495  31.319131  32.307375   \n",
              "3    -20.283150    -20.702256  2.553448  3.476890  40.566301  41.404512   \n",
              "4    -15.002083    -15.838370  2.283960  2.958075  30.004166  31.676739   \n",
              "\n",
              "   d_elpd_waic    d_waic  \n",
              "0    -1.237712  2.475424  \n",
              "1    -0.665209  1.330419  \n",
              "2    -0.494122  0.988244  \n",
              "3    -0.419106  0.838211  \n",
              "4    -0.836286  1.672573  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ab0b0ba-3b5b-4aa3-bae8-bc2e2bd131ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_id</th>\n",
              "      <th>class_label</th>\n",
              "      <th>N</th>\n",
              "      <th>L_logM</th>\n",
              "      <th>L_met</th>\n",
              "      <th>L_3D</th>\n",
              "      <th>Mahal_3D</th>\n",
              "      <th>elpd_waic_1d</th>\n",
              "      <th>elpd_waic_3d</th>\n",
              "      <th>pwaic_1d</th>\n",
              "      <th>pwaic_3d</th>\n",
              "      <th>waic_1d</th>\n",
              "      <th>waic_3d</th>\n",
              "      <th>d_elpd_waic</th>\n",
              "      <th>d_waic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>2.819956</td>\n",
              "      <td>4.194866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-14.223797</td>\n",
              "      <td>-15.461509</td>\n",
              "      <td>1.972777</td>\n",
              "      <td>3.187070</td>\n",
              "      <td>28.447594</td>\n",
              "      <td>30.923018</td>\n",
              "      <td>-1.237712</td>\n",
              "      <td>2.475424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>5.176308</td>\n",
              "      <td>6.248549</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-16.128995</td>\n",
              "      <td>-16.794204</td>\n",
              "      <td>3.074055</td>\n",
              "      <td>3.567468</td>\n",
              "      <td>32.257989</td>\n",
              "      <td>33.588408</td>\n",
              "      <td>-0.665209</td>\n",
              "      <td>1.330419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>3.167812</td>\n",
              "      <td>4.248156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-15.659566</td>\n",
              "      <td>-16.153688</td>\n",
              "      <td>2.009456</td>\n",
              "      <td>3.010495</td>\n",
              "      <td>31.319131</td>\n",
              "      <td>32.307375</td>\n",
              "      <td>-0.494122</td>\n",
              "      <td>0.988244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>3.455950</td>\n",
              "      <td>5.425339</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-20.283150</td>\n",
              "      <td>-20.702256</td>\n",
              "      <td>2.553448</td>\n",
              "      <td>3.476890</td>\n",
              "      <td>40.566301</td>\n",
              "      <td>41.404512</td>\n",
              "      <td>-0.419106</td>\n",
              "      <td>0.838211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>3.371722</td>\n",
              "      <td>4.183941</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-15.002083</td>\n",
              "      <td>-15.838370</td>\n",
              "      <td>2.283960</td>\n",
              "      <td>2.958075</td>\n",
              "      <td>30.004166</td>\n",
              "      <td>31.676739</td>\n",
              "      <td>-0.836286</td>\n",
              "      <td>1.672573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ab0b0ba-3b5b-4aa3-bae8-bc2e2bd131ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ab0b0ba-3b5b-4aa3-bae8-bc2e2bd131ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ab0b0ba-3b5b-4aa3-bae8-bc2e2bd131ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\" - PPC per-survey PDFs: look for structure in z vs logM; persistent structure means model misspecification\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"survey_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"S1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L_logM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9155391947393168,\n        \"min\": 2.8199564838910858,\n        \"max\": 5.176307813045269,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.176307813045269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L_met\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9382816658329386,\n        \"min\": 4.183940631594737,\n        \"max\": 6.248549435325063,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.248549435325063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"L_3D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mahal_3D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elpd_waic_1d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.360714906639062,\n        \"min\": -20.28315033018589,\n        \"max\": -14.22379682585597,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elpd_waic_3d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1319671508698352,\n        \"min\": -20.70225590094924,\n        \"max\": -15.461508989334106,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pwaic_1d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45391245240793193,\n        \"min\": 1.972777247428894,\n        \"max\": 3.0740554332733154,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pwaic_3d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27308780698817353,\n        \"min\": 2.9580750465393066,\n        \"max\": 3.5674679279327393,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"waic_1d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.721429813278124,\n        \"min\": 28.44759365171194,\n        \"max\": 40.56630066037178,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"waic_3d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2639343017396705,\n        \"min\": 30.923017978668213,\n        \"max\": 41.40451180189848,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d_elpd_waic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32617433232843496,\n        \"min\": -1.237712163478136,\n        \"max\": -0.41910557076334953,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d_waic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6523486646568699,\n        \"min\": 0.8382111415266991,\n        \"max\": 2.475424326956272,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   survey_id class_label   N  1d_z_mean   1d_z_sd  1d_frac_|z|>2  \\\n",
              "0          1          S1  20   0.002140  0.916887            0.0   \n",
              "1          2          S1  20   0.005709  0.914354            0.0   \n",
              "2          3          S1  20   0.000918  0.923054            0.0   \n",
              "3          4          S1  20   0.003751  0.921438            0.0   \n",
              "4          5          S1  20   0.004407  0.923618            0.0   \n",
              "\n",
              "   1d_frac_|z|>3  1d_rmse_z  3d_z_mean   3d_z_sd  3d_frac_|z|>2  \\\n",
              "0            0.0   0.893674  -0.005176  0.886848            0.0   \n",
              "1            0.0   0.891220  -0.006863  0.881956            0.0   \n",
              "2            0.0   0.899682  -0.002744  0.881205            0.0   \n",
              "3            0.0   0.898115  -0.006268  0.879959            0.0   \n",
              "4            0.0   0.900242  -0.005080  0.888423            0.0   \n",
              "\n",
              "   3d_frac_|z|>3  3d_rmse_z  \n",
              "0            0.0   0.864408  \n",
              "1            0.0   0.859651  \n",
              "2            0.0   0.858897  \n",
              "3            0.0   0.857701  \n",
              "4            0.0   0.865943  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-872552d7-70d7-4630-85cd-4c3808425e2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_id</th>\n",
              "      <th>class_label</th>\n",
              "      <th>N</th>\n",
              "      <th>1d_z_mean</th>\n",
              "      <th>1d_z_sd</th>\n",
              "      <th>1d_frac_|z|&gt;2</th>\n",
              "      <th>1d_frac_|z|&gt;3</th>\n",
              "      <th>1d_rmse_z</th>\n",
              "      <th>3d_z_mean</th>\n",
              "      <th>3d_z_sd</th>\n",
              "      <th>3d_frac_|z|&gt;2</th>\n",
              "      <th>3d_frac_|z|&gt;3</th>\n",
              "      <th>3d_rmse_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.002140</td>\n",
              "      <td>0.916887</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.893674</td>\n",
              "      <td>-0.005176</td>\n",
              "      <td>0.886848</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.864408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.005709</td>\n",
              "      <td>0.914354</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.891220</td>\n",
              "      <td>-0.006863</td>\n",
              "      <td>0.881956</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.859651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000918</td>\n",
              "      <td>0.923054</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.899682</td>\n",
              "      <td>-0.002744</td>\n",
              "      <td>0.881205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.858897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.003751</td>\n",
              "      <td>0.921438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.898115</td>\n",
              "      <td>-0.006268</td>\n",
              "      <td>0.879959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.857701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>S1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>0.923618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.900242</td>\n",
              "      <td>-0.005080</td>\n",
              "      <td>0.888423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.865943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-872552d7-70d7-4630-85cd-4c3808425e2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-872552d7-70d7-4630-85cd-4c3808425e2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-872552d7-70d7-4630-85cd-4c3808425e2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\" - PPC per-survey PDFs: look for structure in z vs logM; persistent structure means model misspecification\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"survey_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"S1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1d_z_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018851676579561504,\n        \"min\": 0.0009177355881256454,\n        \"max\": 0.005708610142824966,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.005708610142824966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1d_z_sd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004061096561259923,\n        \"min\": 0.9143537131888438,\n        \"max\": 0.9236179778543392,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9143537131888438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1d_frac_|z|>2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1d_frac_|z|>3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1d_rmse_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003954929087275577,\n        \"min\": 0.8912200432053118,\n        \"max\": 0.9002422343010729,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8912200432053118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3d_z_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0015772216711396373,\n        \"min\": -0.0068634078583490795,\n        \"max\": -0.002743960065934353,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.0068634078583490795\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3d_z_sd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003724220027599478,\n        \"min\": 0.8799594081901562,\n        \"max\": 0.8884234447538402,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8819556441631405\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3d_frac_|z|>2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3d_frac_|z|>3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3d_rmse_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0036283606886303153,\n        \"min\": 0.8577012387789436,\n        \"max\": 0.8659429593215229,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8596514274548082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x644 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'beta_s_mean'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'beta_s_mean'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1654834156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0m_clean_ax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta_s_mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta_s_sd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'beta_s_mean'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x644 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}